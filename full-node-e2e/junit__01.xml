<?xml version="1.0" encoding="UTF-8"?>
  <testsuite tests="84" failures="16" time="3412.775211958">
      <testcase name="[k8s.io] Density [Serial] [Slow] create a batch of pods latency/resource should be within limit when create 10 pods with 0s interval [Benchmark]" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Container Runtime Conformance Test container runtime conformance blackbox test when running a container with a new image should not be able to pull image from invalid registry [Conformance]" classname="E2eNode Suite" time="19.094620857"></testcase>
      <testcase name="[k8s.io] NodeProblemDetector [k8s.io] SystemLogMonitor should generate node condition and events for corresponding errors" classname="E2eNode Suite" time="104.170399921">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/node_problem_detector.go:341&#xA;Timed out after 60.000s.&#xA;Expected success, but got an error:&#xA;    &lt;*errors.errorString | 0xc420bcf6c0&gt;: {&#xA;        s: &#34;expect event number 3, got 0: []&#34;,&#xA;    }&#xA;    expect event number 3, got 0: []&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/node_problem_detector.go:326</failure>
          <system-out>[BeforeEach] [k8s.io] NodeProblemDetector&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 11:20:00.327: INFO: Skipping waiting for service account&#xA;[BeforeEach] [k8s.io] NodeProblemDetector&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/node_problem_detector.go:61&#xA;[BeforeEach] [k8s.io] SystemLogMonitor&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/node_problem_detector.go:228&#xA;�[1mSTEP�[0m: Calculate Lookback duration&#xA;�[1mSTEP�[0m: Generate event list options&#xA;�[1mSTEP�[0m: Create the test log file&#xA;�[1mSTEP�[0m: Create config map for the node problem detector&#xA;�[1mSTEP�[0m: Create the node problem detector&#xA;[It] should generate node condition and events for corresponding errors&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/node_problem_detector.go:341&#xA;�[1mSTEP�[0m: should generate default node condition&#xA;�[1mSTEP�[0m: Wait for 0 events generated&#xA;�[1mSTEP�[0m: Make sure only 0 events generated&#xA;�[1mSTEP�[0m: Make sure node condition &#34;TestCondition&#34; is set&#xA;�[1mSTEP�[0m: Make sure node condition &#34;TestCondition&#34; is stable&#xA;�[1mSTEP�[0m: should not generate events for too old log&#xA;�[1mSTEP�[0m: Inject 3 logs: &#34;temporary error&#34;&#xA;�[1mSTEP�[0m: Wait for 0 events generated&#xA;�[1mSTEP�[0m: Make sure only 0 events generated&#xA;�[1mSTEP�[0m: Make sure node condition &#34;TestCondition&#34; is set&#xA;�[1mSTEP�[0m: Make sure node condition &#34;TestCondition&#34; is stable&#xA;�[1mSTEP�[0m: should not change node condition for too old log&#xA;�[1mSTEP�[0m: Inject 1 logs: &#34;permanent error 1&#34;&#xA;�[1mSTEP�[0m: Wait for 0 events generated&#xA;�[1mSTEP�[0m: Make sure only 0 events generated&#xA;�[1mSTEP�[0m: Make sure node condition &#34;TestCondition&#34; is set&#xA;�[1mSTEP�[0m: Make sure node condition &#34;TestCondition&#34; is stable&#xA;�[1mSTEP�[0m: should generate event for old log within lookback duration&#xA;�[1mSTEP�[0m: Inject 3 logs: &#34;temporary error&#34;&#xA;�[1mSTEP�[0m: Wait for 3 events generated&#xA;[AfterEach] [k8s.io] SystemLogMonitor&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/node_problem_detector.go:363&#xA;�[1mSTEP�[0m: Get node problem detector log&#xA;Mar 21 11:21:34.359: INFO: Node Problem Detector logs:&#xA; failed to open log file &#34;/var/log/pods/527a2ab8-0e28-11e7-a3dc-42010a8c0008/node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008_1.log&#34;: open /var/log/pods/527a2ab8-0e28-11e7-a3dc-42010a8c0008/node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008_1.log: no such file or directory&#xA;�[1mSTEP�[0m: Delete the node problem detector&#xA;�[1mSTEP�[0m: Wait for the node problem detector to disappear&#xA;Mar 21 11:21:34.366: INFO: Waiting for pod node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008 to disappear&#xA;Mar 21 11:21:34.367: INFO: Pod node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008 no longer exists&#xA;�[1mSTEP�[0m: Delete the config map&#xA;�[1mSTEP�[0m: Clean up the events&#xA;�[1mSTEP�[0m: Clean up the node condition&#xA;�[1mSTEP�[0m: Clean up the temporary directory&#xA;[AfterEach] [k8s.io] NodeProblemDetector&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-node-problem-detector-m7tl3&#34;.&#xA;�[1mSTEP�[0m: Found 7 events.&#xA;Mar 21 11:21:34.378: INFO: At 2017-03-21 11:20:01 +0000 UTC - event for node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/node-problem-detector:v0.3.0&#34; already present on machine&#xA;Mar 21 11:21:34.378: INFO: At 2017-03-21 11:20:02 +0000 UTC - event for node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id ffa6541ff909147b3b0493194b92e80b0cb51b9b1f085e56c5f8dc749e130540&#xA;Mar 21 11:21:34.378: INFO: At 2017-03-21 11:20:02 +0000 UTC - event for node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Failed: Failed to start container with id ffa6541ff909147b3b0493194b92e80b0cb51b9b1f085e56c5f8dc749e130540 with error: rpc error: code = 2 desc = failed to create symbolic link &#34;/var/log/pods/527a2ab8-0e28-11e7-a3dc-42010a8c0008/node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008_0.log&#34; to the container log file &#34;&#34; for container &#34;ffa6541ff909147b3b0493194b92e80b0cb51b9b1f085e56c5f8dc749e130540&#34;: symlink  /var/log/pods/527a2ab8-0e28-11e7-a3dc-42010a8c0008/node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008_0.log: no such file or directory&#xA;Mar 21 11:21:34.378: INFO: At 2017-03-21 11:20:02 +0000 UTC - event for node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008&#34; with rpc error: code = 2 desc = failed to create symbolic link &#34;/var/log/pods/527a2ab8-0e28-11e7-a3dc-42010a8c0008/node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008_0.log&#34; to the container log file &#34;&#34; for container &#34;ffa6541ff909147b3b0493194b92e80b0cb51b9b1f085e56c5f8dc749e130540&#34;: symlink  /var/log/pods/527a2ab8-0e28-11e7-a3dc-42010a8c0008/node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008_0.log: no such file or directory: &#34;Start Container Failed&#34;&#xA;&#xA;Mar 21 11:21:34.378: INFO: At 2017-03-21 11:20:55 +0000 UTC - event for node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id b295164b19e24c3ed198fac2389ce114c2ac84605ab65c0d38e37e6ce39de204&#xA;Mar 21 11:21:34.379: INFO: At 2017-03-21 11:20:55 +0000 UTC - event for node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Failed: Failed to start container with id b295164b19e24c3ed198fac2389ce114c2ac84605ab65c0d38e37e6ce39de204 with error: rpc error: code = 2 desc = failed to create symbolic link &#34;/var/log/pods/527a2ab8-0e28-11e7-a3dc-42010a8c0008/node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008_1.log&#34; to the container log file &#34;&#34; for container &#34;b295164b19e24c3ed198fac2389ce114c2ac84605ab65c0d38e37e6ce39de204&#34;: symlink  /var/log/pods/527a2ab8-0e28-11e7-a3dc-42010a8c0008/node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008_1.log: no such file or directory&#xA;Mar 21 11:21:34.379: INFO: At 2017-03-21 11:20:55 +0000 UTC - event for node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008&#34; with rpc error: code = 2 desc = failed to create symbolic link &#34;/var/log/pods/527a2ab8-0e28-11e7-a3dc-42010a8c0008/node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008_1.log&#34; to the container log file &#34;&#34; for container &#34;b295164b19e24c3ed198fac2389ce114c2ac84605ab65c0d38e37e6ce39de204&#34;: symlink  /var/log/pods/527a2ab8-0e28-11e7-a3dc-42010a8c0008/node-problem-detector-5279a0fd-0e28-11e7-8677-42010a8c0008_1.log: no such file or directory: &#34;Start Container Failed&#34;&#xA;&#xA;Mar 21 11:21:34.382: INFO: POD                                            NODE        PHASE    GRACE  CONDITIONS&#xA;Mar 21 11:21:34.382: INFO: pod-init-60327567-0e28-11e7-9911-42010a8c0008  frakti-e2e  Pending         [{Initialized False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:20:23 +0000 UTC ContainersNotInitialized containers with incomplete status: [init1 init2]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:20:23 +0000 UTC ContainersNotReady containers with unready status: [run1]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:20:29 +0000 UTC  }]&#xA;Mar 21 11:21:34.382: INFO: &#xA;Mar 21 11:21:34.384: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 11:21:34.385: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:242,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 11:21:30 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 11:21:30 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 11:21:30 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 11:21:30 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 11:21:34.385: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 11:21:34.386: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 11:21:34.391: INFO: pod-init-60327567-0e28-11e7-9911-42010a8c0008 started at 2017-03-21 11:20:23 +0000 UTC (2+1 container statuses recorded)&#xA;Mar 21 11:21:34.391: INFO: &#x9;Init container init1 ready: false, restart count 2&#xA;Mar 21 11:21:34.391: INFO: &#x9;Init container init2 ready: false, restart count 0&#xA;Mar 21 11:21:34.391: INFO: &#x9;Container run1 ready: false, restart count 0&#xA;Mar 21 11:21:34.453: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 11:21:34.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-node-problem-detector-m7tl3&#34; for this suite.&#xA;Mar 21 11:21:44.482: INFO: namespace: e2e-tests-node-problem-detector-m7tl3, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Density [Serial] [Slow] create a batch of pods with higher API QPS latency/resource should be within limit when create 105 pods with 300ms interval (QPS 60) [Benchmark]" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Projected should be consumable from pods in volume with defaultMode set [Conformance] [Volume]" classname="E2eNode Suite" time="18.067111652"></testcase>
      <testcase name="[k8s.io] Probing container should be restarted with a exec &#34;cat /tmp/health&#34; liveness probe [Conformance]" classname="E2eNode Suite" time="42.081205298"></testcase>
      <testcase name="[k8s.io] Container Runtime Conformance Test container runtime conformance blackbox test when starting a container that exits should report termination message if TerminationMessagePath is set [Conformance]" classname="E2eNode Suite" time="21.063504252"></testcase>
      <testcase name="[k8s.io] Networking [k8s.io] Granular Checks: Pods should function for node-pod communication: udp [Conformance]" classname="E2eNode Suite" time="330.120942471">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:59&#xA;Expected error:&#xA;    &lt;*errors.errorString | 0xc42042dd10&gt;: {&#xA;        s: &#34;timed out waiting for the condition&#34;,&#xA;    }&#xA;    timed out waiting for the condition&#xA;not to have occurred&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/networking_utils.go:550</failure>
          <system-out>[BeforeEach] [k8s.io] Networking&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 11:23:05.720: INFO: Skipping waiting for service account&#xA;[It] should function for node-pod communication: udp [Conformance]&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:59&#xA;�[1mSTEP�[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-0j64r&#xA;�[1mSTEP�[0m: creating a selector&#xA;�[1mSTEP�[0m: Creating the service pods in kubernetes&#xA;Mar 21 11:23:05.720: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable&#xA;Mar 21 11:28:05.733: INFO: Unexpected error occurred: timed out waiting for the condition&#xA;[AfterEach] [k8s.io] Networking&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-pod-network-test-0j64r&#34;.&#xA;�[1mSTEP�[0m: Found 3 events.&#xA;Mar 21 11:28:05.736: INFO: At 2017-03-21 11:23:10 +0000 UTC - event for netserver-0: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/netexec:1.7&#34; already present on machine&#xA;Mar 21 11:28:05.736: INFO: At 2017-03-21 11:23:10 +0000 UTC - event for netserver-0: {kubelet frakti-e2e} Created: Created container with id 9b75e6e37018b349d70e41cd38f73c35c5a523ccb06a772669fb194a0d80ee15&#xA;Mar 21 11:28:05.736: INFO: At 2017-03-21 11:23:10 +0000 UTC - event for netserver-0: {kubelet frakti-e2e} Started: Started container with id 9b75e6e37018b349d70e41cd38f73c35c5a523ccb06a772669fb194a0d80ee15&#xA;Mar 21 11:28:05.738: INFO: POD          NODE        PHASE    GRACE  CONDITIONS&#xA;Mar 21 11:28:05.738: INFO: netserver-0  frakti-e2e  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:23:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:23:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:24:42 +0000 UTC  }]&#xA;Mar 21 11:28:05.738: INFO: &#xA;Mar 21 11:28:05.740: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 11:28:05.741: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:699,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 11:28:02 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 11:28:02 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 11:28:02 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 11:28:02 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 11:28:05.741: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 11:28:05.742: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 11:28:05.744: INFO: netserver-0 started at 2017-03-21 11:23:05 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 11:28:05.744: INFO: &#x9;Container webserver ready: false, restart count 0&#xA;Mar 21 11:28:05.801: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 11:28:05.801: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m1.029684s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 11:28:05.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-pod-network-test-0j64r&#34; for this suite.&#xA;Mar 21 11:28:35.834: INFO: namespace: e2e-tests-pod-network-test-0j64r, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Projected should be consumable from pods in volume [Conformance] [Volume]" classname="E2eNode Suite" time="18.070011906"></testcase>
      <testcase name="[k8s.io] Projected should be consumable from pods in volume with defaultMode set [Conformance] [Volume]" classname="E2eNode Suite" time="18.065464182"></testcase>
      <testcase name="[k8s.io] Container Runtime Conformance Test container runtime conformance blackbox test when starting a container that exits should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogOnError is set" classname="E2eNode Suite" time="16.070088401"></testcase>
      <testcase name="[k8s.io] Container Runtime Conformance Test container runtime conformance blackbox test when starting a container that exits should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [Conformance]" classname="E2eNode Suite" time="17.060580737"></testcase>
      <testcase name="[k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [Conformance]" classname="E2eNode Suite" time="136.192572176"></testcase>
      <testcase name="[k8s.io] Projected should update annotations on modification [Conformance] [Volume]" classname="E2eNode Suite" time="38.593552602"></testcase>
      <testcase name="[k8s.io] Projected should be consumable from pods in volume as non-root with defaultMode and fsGroup set [Conformance] [Volume]" classname="E2eNode Suite" time="18.070425793"></testcase>
      <testcase name="[k8s.io] GCP Volumes [k8s.io] GlusterFS should be mountable [Volume]" classname="E2eNode Suite" time="10.04360155">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Sysctls should support unsafe sysctls which are actually whitelisted" classname="E2eNode Suite" time="12.044305853000001">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Resource-usage [Serial] [Slow] regular resource usage tracking resource tracking for 0 pods per node [Benchmark]" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Container Manager Misc [Serial] Validate OOM score adjustments once the node is setup burstable container&#39;s oom-score-adj should be between [2, 1000)" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [Conformance] [Volume]" classname="E2eNode Suite" time="16.058106313"></testcase>
      <testcase name="[k8s.io] ConfigMap updates should be reflected in volume [Conformance] [Volume]" classname="E2eNode Suite" time="116.296074808"></testcase>
      <testcase name="[k8s.io] Secrets should be consumable from pods in volume with defaultMode set [Conformance] [Volume]" classname="E2eNode Suite" time="16.074353418"></testcase>
      <testcase name="[k8s.io] MirrorPod when create a mirror pod  should be updated when static pod updated [Conformance]" classname="E2eNode Suite" time="35.073361195"></testcase>
      <testcase name="[k8s.io] Networking [k8s.io] Granular Checks: Pods should function for intra-pod communication: http [Conformance]" classname="E2eNode Suite" time="330.129698846">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:38&#xA;Expected error:&#xA;    &lt;*errors.errorString | 0xc42042dd10&gt;: {&#xA;        s: &#34;timed out waiting for the condition&#34;,&#xA;    }&#xA;    timed out waiting for the condition&#xA;not to have occurred&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/networking_utils.go:550</failure>
          <system-out>[BeforeEach] [k8s.io] Networking&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 11:36:23.585: INFO: Skipping waiting for service account&#xA;[It] should function for intra-pod communication: http [Conformance]&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:38&#xA;�[1mSTEP�[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-sbxds&#xA;�[1mSTEP�[0m: creating a selector&#xA;�[1mSTEP�[0m: Creating the service pods in kubernetes&#xA;Mar 21 11:36:23.585: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable&#xA;Mar 21 11:41:23.594: INFO: Unexpected error occurred: timed out waiting for the condition&#xA;[AfterEach] [k8s.io] Networking&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-pod-network-test-sbxds&#34;.&#xA;�[1mSTEP�[0m: Found 3 events.&#xA;Mar 21 11:41:23.597: INFO: At 2017-03-21 11:36:29 +0000 UTC - event for netserver-0: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/netexec:1.7&#34; already present on machine&#xA;Mar 21 11:41:23.597: INFO: At 2017-03-21 11:36:29 +0000 UTC - event for netserver-0: {kubelet frakti-e2e} Created: Created container with id 416a4dd9db509745fae5348c934317686e857092452df91c4559777dfa795e74&#xA;Mar 21 11:41:23.597: INFO: At 2017-03-21 11:36:29 +0000 UTC - event for netserver-0: {kubelet frakti-e2e} Started: Started container with id 416a4dd9db509745fae5348c934317686e857092452df91c4559777dfa795e74&#xA;Mar 21 11:41:23.600: INFO: POD          NODE        PHASE    GRACE  CONDITIONS&#xA;Mar 21 11:41:23.600: INFO: netserver-0  frakti-e2e  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:36:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:36:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:38:00 +0000 UTC  }]&#xA;Mar 21 11:41:23.600: INFO: &#xA;Mar 21 11:41:23.601: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 11:41:23.603: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:1734,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 11:41:15 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 11:41:15 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 11:41:15 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 11:41:15 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 11:41:23.603: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 11:41:23.604: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 11:41:23.606: INFO: netserver-0 started at 2017-03-21 11:36:23 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 11:41:23.606: INFO: &#x9;Container webserver ready: false, restart count 0&#xA;Mar 21 11:41:23.666: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 11:41:23.666: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m5.176808s}&#xA;Mar 21 11:41:23.666: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m5.16431s}&#xA;Mar 21 11:41:23.666: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.5 Latency:2m1.06178s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 11:41:23.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-pod-network-test-sbxds&#34; for this suite.&#xA;Mar 21 11:41:53.699: INFO: namespace: e2e-tests-pod-network-test-sbxds, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Container Manager Misc [Serial] Validate OOM score adjustments once the node is setup docker daemon&#39;s oom-score-adj should be -999" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Downward API should provide pod IP as an env var [Conformance]" classname="E2eNode Suite" time="18.184239034">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:84&#xA;Expected error:&#xA;    &lt;*errors.errorString | 0xc420b50540&gt;: {&#xA;        s: &#34;expected pod \&#34;downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008\&#34; success: &lt;nil&gt;&#34;,&#xA;    }&#xA;    expected pod &#34;downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008&#34; success: &lt;nil&gt;&#xA;not to have occurred&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:2197</failure>
          <system-out>[BeforeEach] [k8s.io] Downward API&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 11:41:53.720: INFO: Skipping waiting for service account&#xA;[It] should provide pod IP as an env var [Conformance]&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:84&#xA;�[1mSTEP�[0m: Creating a pod to test downward api env vars&#xA;Mar 21 11:41:53.722: INFO: Waiting up to 5m0s for pod downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008 status to be success or failure&#xA;Mar 21 11:41:53.724: INFO: Waiting for pod downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-downward-api-cc9jh&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (2.112327ms elapsed)&#xA;Mar 21 11:41:55.726: INFO: Waiting for pod downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-downward-api-cc9jh&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (2.004268323s elapsed)&#xA;Mar 21 11:41:57.728: INFO: Waiting for pod downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-downward-api-cc9jh&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (4.006646608s elapsed)&#xA;Mar 21 11:41:59.730: INFO: Waiting for pod downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-downward-api-cc9jh&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (6.008624885s elapsed)&#xA;Mar 21 11:42:01.740: INFO: Output of node &#34;frakti-e2e&#34; pod &#34;downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008&#34; container &#34;dapi-container&#34;: exec failed: No such file or directory&#xA;&#xA;�[1mSTEP�[0m: delete the pod&#xA;Mar 21 11:42:01.750: INFO: Waiting for pod downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008 to disappear&#xA;Mar 21 11:42:01.751: INFO: Pod downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008 no longer exists&#xA;Mar 21 11:42:01.751: INFO: Unexpected error occurred: expected pod &#34;downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008&#34; success: &lt;nil&gt;&#xA;[AfterEach] [k8s.io] Downward API&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-downward-api-cc9jh&#34;.&#xA;�[1mSTEP�[0m: Found 3 events.&#xA;Mar 21 11:42:01.754: INFO: At 2017-03-21 11:42:00 +0000 UTC - event for downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 11:42:01.754: INFO: At 2017-03-21 11:42:00 +0000 UTC - event for downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id 42db8793513d3f44bf4afecd1119907895ff96b3ba73700907edd4eba69cee3b&#xA;Mar 21 11:42:01.754: INFO: At 2017-03-21 11:42:00 +0000 UTC - event for downward-api-61517bd3-0e2b-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Started: Started container with id 42db8793513d3f44bf4afecd1119907895ff96b3ba73700907edd4eba69cee3b&#xA;Mar 21 11:42:01.757: INFO: POD                                                   NODE        PHASE    GRACE  CONDITIONS&#xA;Mar 21 11:42:01.757: INFO: metadata-volume-645ecec3-0e2b-11e7-9911-42010a8c0008  frakti-e2e  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:41:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:41:58 +0000 UTC ContainersNotReady containers with unready status: [client-container]}]&#xA;Mar 21 11:42:01.757: INFO: &#xA;Mar 21 11:42:01.759: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 11:42:01.761: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:1789,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 11:41:55 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 11:41:55 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 11:41:55 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 11:41:55 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 11:42:01.761: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 11:42:01.762: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 11:42:01.765: INFO: metadata-volume-645ecec3-0e2b-11e7-9911-42010a8c0008 started at 2017-03-21 11:41:58 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 11:42:01.765: INFO: &#x9;Container client-container ready: false, restart count 0&#xA;Mar 21 11:42:01.863: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 11:42:01.863: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m5.176808s}&#xA;Mar 21 11:42:01.863: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m5.16431s}&#xA;Mar 21 11:42:01.863: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.5 Latency:2m1.062762s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 11:42:01.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-downward-api-cc9jh&#34; for this suite.&#xA;Mar 21 11:42:11.899: INFO: namespace: e2e-tests-downward-api-cc9jh, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] SimpleMount should be able to mount an emptydir on a container" classname="E2eNode Suite" time="38.05438338"></testcase>
      <testcase name="[k8s.io] GPU [Serial] attempt to use GPUs if available setup the node and create pods to test gpus" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] GCP Volumes [k8s.io] NFSv3 should be mountable for NFSv3 [Volume]" classname="E2eNode Suite" time="15.05530558">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] PrivilegedPod should enable privileged commands" classname="E2eNode Suite" time="54.243612798"></testcase>
      <testcase name="[k8s.io] Density [Serial] [Slow] create a batch of pods latency/resource should be within limit when create 105 pods with 0s interval [Benchmark]" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] ConfigMap should be consumable from pods in volume as non-root [Conformance] [Volume]" classname="E2eNode Suite" time="18.076861005"></testcase>
      <testcase name="[k8s.io] Projected should be consumable from pods in volume with mappings as non-root with FSGroup [Feature:FSGroup] [Volume]" classname="E2eNode Suite" time="16.063982436"></testcase>
      <testcase name="[k8s.io] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [Volume]" classname="E2eNode Suite" time="26.161636656"></testcase>
      <testcase name="[k8s.io] Projected should be able to mount in a volume regardless of a different secret existing with same name in different namespace [Volume]" classname="E2eNode Suite" time="28.117918847"></testcase>
      <testcase name="[k8s.io] EmptyDir volumes should support (root,0777,tmpfs) [Conformance] [Volume]" classname="E2eNode Suite" time="18.078213651"></testcase>
      <testcase name="[k8s.io] EmptyDir volumes should support (root,0777,default) [Conformance] [Volume]" classname="E2eNode Suite" time="18.0684885"></testcase>
      <testcase name="[k8s.io] Probing container should *not* be restarted with a exec &#34;cat /tmp/health&#34; liveness probe [Conformance]" classname="E2eNode Suite" time="138.311019521">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:149&#xA;Mar 21 11:48:11.996: pod e2e-tests-container-probe-f6pc6/liveness-exec - expected number of restarts: 0, found restarts: 4&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:404</failure>
          <system-out>[BeforeEach] [k8s.io] Probing container&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 11:46:03.852: INFO: Skipping waiting for service account&#xA;[BeforeEach] [k8s.io] Probing container&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48&#xA;[It] should *not* be restarted with a exec &#34;cat /tmp/health&#34; liveness probe [Conformance]&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:149&#xA;�[1mSTEP�[0m: Creating pod liveness-exec in namespace e2e-tests-container-probe-f6pc6&#xA;Mar 21 11:46:11.858: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-f6pc6&#xA;�[1mSTEP�[0m: checking the pod&#39;s current state and verifying that restartCount is present&#xA;Mar 21 11:46:11.860: INFO: Initial restart count of pod liveness-exec is 0&#xA;Mar 21 11:46:35.886: INFO: Restart count of pod e2e-tests-container-probe-f6pc6/liveness-exec is now 1 (24.025986707s elapsed)&#xA;Mar 21 11:46:55.907: INFO: Restart count of pod e2e-tests-container-probe-f6pc6/liveness-exec is now 2 (44.047375543s elapsed)&#xA;Mar 21 11:47:15.928: INFO: Restart count of pod e2e-tests-container-probe-f6pc6/liveness-exec is now 3 (1m4.068782393s elapsed)&#xA;Mar 21 11:47:35.950: INFO: Restart count of pod e2e-tests-container-probe-f6pc6/liveness-exec is now 4 (1m24.09056364s elapsed)&#xA;Mar 21 11:48:11.996: INFO: pod e2e-tests-container-probe-f6pc6/liveness-exec - expected number of restarts: 0, found restarts: 4&#xA;�[1mSTEP�[0m: deleting the pod&#xA;[AfterEach] [k8s.io] Probing container&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-container-probe-f6pc6&#34;.&#xA;�[1mSTEP�[0m: Found 18 events.&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:46:09 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Created: Created container with id ad8c2cad7b411a05fadc5cc74dff6403c8b947b3a8743411679c1cf92df3be0b&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:46:09 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Started: Started container with id ad8c2cad7b411a05fadc5cc74dff6403c8b947b3a8743411679c1cf92df3be0b&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:46:09 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:46:33 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Created: Created container with id 6e53dcb94c8a37083dfb510323ea994eb3536f932caf2250256a8ae5296ad22c&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:46:33 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Killing: Killing container with id hyper://ad8c2cad7b411a05fadc5cc74dff6403c8b947b3a8743411679c1cf92df3be0b:pod &#34;liveness-exec_e2e-tests-container-probe-f6pc6(f668ac17-0e2b-11e7-a3dc-42010a8c0008)&#34; container &#34;liveness&#34; is unhealthy, it will be killed and re-created.&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:46:34 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Started: Started container with id 6e53dcb94c8a37083dfb510323ea994eb3536f932caf2250256a8ae5296ad22c&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:46:53 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Killing: Killing container with id hyper://6e53dcb94c8a37083dfb510323ea994eb3536f932caf2250256a8ae5296ad22c:pod &#34;liveness-exec_e2e-tests-container-probe-f6pc6(f668ac17-0e2b-11e7-a3dc-42010a8c0008)&#34; container &#34;liveness&#34; is unhealthy, it will be killed and re-created.&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:46:53 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Created: Created container with id 97bb76ee60eff67046d1a6744882fb6dd847fce830e21043be8c6ea9dc738851&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:46:54 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Started: Started container with id 97bb76ee60eff67046d1a6744882fb6dd847fce830e21043be8c6ea9dc738851&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:47:13 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Started: Started container with id 209683362ba8437495b6be42ca2a61522f9c061be8f2ca13d2207b814749851c&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:47:13 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Created: Created container with id 209683362ba8437495b6be42ca2a61522f9c061be8f2ca13d2207b814749851c&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:47:13 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Killing: Killing container with id hyper://97bb76ee60eff67046d1a6744882fb6dd847fce830e21043be8c6ea9dc738851:pod &#34;liveness-exec_e2e-tests-container-probe-f6pc6(f668ac17-0e2b-11e7-a3dc-42010a8c0008)&#34; container &#34;liveness&#34; is unhealthy, it will be killed and re-created.&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:47:33 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Killing: Killing container with id hyper://209683362ba8437495b6be42ca2a61522f9c061be8f2ca13d2207b814749851c:pod &#34;liveness-exec_e2e-tests-container-probe-f6pc6(f668ac17-0e2b-11e7-a3dc-42010a8c0008)&#34; container &#34;liveness&#34; is unhealthy, it will be killed and re-created.&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:47:33 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Created: Created container with id 26cd0166ba6fef74ef8b1caa08aec2120574c08e7966094e6923585277d7186c&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:47:34 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Started: Started container with id 26cd0166ba6fef74ef8b1caa08aec2120574c08e7966094e6923585277d7186c&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:47:53 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} Killing: Killing container with id hyper://26cd0166ba6fef74ef8b1caa08aec2120574c08e7966094e6923585277d7186c:pod &#34;liveness-exec_e2e-tests-container-probe-f6pc6(f668ac17-0e2b-11e7-a3dc-42010a8c0008)&#34; container &#34;liveness&#34; is unhealthy, it will be killed and re-created.&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:47:53 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} BackOff: Back-off restarting failed container&#xA;Mar 21 11:48:12.007: INFO: At 2017-03-21 11:47:53 +0000 UTC - event for liveness-exec: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;liveness&#34; with CrashLoopBackOff: &#34;Back-off 40s restarting failed container=liveness pod=liveness-exec_e2e-tests-container-probe-f6pc6(f668ac17-0e2b-11e7-a3dc-42010a8c0008)&#34;&#xA;&#xA;Mar 21 11:48:12.012: INFO: POD                                      NODE        PHASE    GRACE  CONDITIONS&#xA;Mar 21 11:48:12.012: INFO: pod38cbdf65-0e2c-11e7-9911-42010a8c0008  frakti-e2e  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:47:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:48:08 +0000 UTC ContainersNotReady containers with unready status: [container38cbf44f-0e2c-11e7-9911-42010a8c0008]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:48:02 +0000 UTC  }]&#xA;Mar 21 11:48:12.012: INFO: &#xA;Mar 21 11:48:12.014: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 11:48:12.016: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:2459,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 11:48:07 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 11:48:07 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 11:48:07 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 11:48:07 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 11:48:12.016: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 11:48:12.018: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 11:48:12.021: INFO: pod38cbdf65-0e2c-11e7-9911-42010a8c0008 started at 2017-03-21 11:47:55 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 11:48:12.021: INFO: &#x9;Container container38cbf44f-0e2c-11e7-9911-42010a8c0008 ready: false, restart count 0&#xA;Mar 21 11:48:12.119: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 11:48:12.119: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m5.357876s}&#xA;Mar 21 11:48:12.120: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m5.314164s}&#xA;Mar 21 11:48:12.120: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.5 Latency:2m1.114117s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 11:48:12.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-container-probe-f6pc6&#34; for this suite.&#xA;Mar 21 11:48:22.156: INFO: namespace: e2e-tests-container-probe-f6pc6, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Probing container should be restarted with a docker exec liveness probe with timeout [Conformance]" classname="E2eNode Suite" time="15.041856767">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Downward API volume should update annotations on modification [Conformance] [Volume]" classname="E2eNode Suite" time="38.569806172"></testcase>
      <testcase name="[k8s.io] Container Runtime Conformance Test container runtime conformance blackbox test when running a container with a new image should be able to pull from private registry with secret [Conformance]" classname="E2eNode Suite" time="19.1225703"></testcase>
      <testcase name="[k8s.io] ConfigMap should be consumable from pods in volume with mappings [Conformance] [Volume]" classname="E2eNode Suite" time="23.072686417"></testcase>
      <testcase name="[k8s.io] Probing container should have monotonically increasing restart count [Conformance] [Slow]" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete" classname="E2eNode Suite" time="30.064595576"></testcase>
      <testcase name="[k8s.io] EmptyDir volumes should support (non-root,0777,default) [Conformance] [Volume]" classname="E2eNode Suite" time="18.144451028">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:117&#xA;Expected error:&#xA;    &lt;*errors.errorString | 0xc420e5d190&gt;: {&#xA;        s: &#34;expected pod \&#34;pod-93e261b8-0e2c-11e7-8677-42010a8c0008\&#34; success: &lt;nil&gt;&#34;,&#xA;    }&#xA;    expected pod &#34;pod-93e261b8-0e2c-11e7-8677-42010a8c0008&#34; success: &lt;nil&gt;&#xA;not to have occurred&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:2197</failure>
          <system-out>[BeforeEach] [k8s.io] EmptyDir volumes&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 11:50:28.052: INFO: Skipping waiting for service account&#xA;[It] should support (non-root,0777,default) [Conformance] [Volume]&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:117&#xA;�[1mSTEP�[0m: Creating a pod to test emptydir 0777 on node default medium&#xA;Mar 21 11:50:28.054: INFO: Waiting up to 5m0s for pod pod-93e261b8-0e2c-11e7-8677-42010a8c0008 status to be success or failure&#xA;Mar 21 11:50:28.055: INFO: Waiting for pod pod-93e261b8-0e2c-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-emptydir-vl9r1&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (1.0674ms elapsed)&#xA;Mar 21 11:50:30.057: INFO: Waiting for pod pod-93e261b8-0e2c-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-emptydir-vl9r1&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (2.003171208s elapsed)&#xA;Mar 21 11:50:32.059: INFO: Waiting for pod pod-93e261b8-0e2c-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-emptydir-vl9r1&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (4.005112821s elapsed)&#xA;Mar 21 11:50:34.061: INFO: Waiting for pod pod-93e261b8-0e2c-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-emptydir-vl9r1&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (6.007284754s elapsed)&#xA;Mar 21 11:50:36.069: INFO: Output of node &#34;frakti-e2e&#34; pod &#34;pod-93e261b8-0e2c-11e7-8677-42010a8c0008&#34; container &#34;test-container&#34;: &#xA;�[1mSTEP�[0m: delete the pod&#xA;Mar 21 11:50:36.073: INFO: Waiting for pod pod-93e261b8-0e2c-11e7-8677-42010a8c0008 to disappear&#xA;Mar 21 11:50:36.074: INFO: Pod pod-93e261b8-0e2c-11e7-8677-42010a8c0008 no longer exists&#xA;Mar 21 11:50:36.074: INFO: Unexpected error occurred: expected pod &#34;pod-93e261b8-0e2c-11e7-8677-42010a8c0008&#34; success: &lt;nil&gt;&#xA;[AfterEach] [k8s.io] EmptyDir volumes&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-emptydir-vl9r1&#34;.&#xA;�[1mSTEP�[0m: Found 3 events.&#xA;Mar 21 11:50:36.076: INFO: At 2017-03-21 11:50:33 +0000 UTC - event for pod-93e261b8-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/mounttest-user:0.5&#34; already present on machine&#xA;Mar 21 11:50:36.076: INFO: At 2017-03-21 11:50:33 +0000 UTC - event for pod-93e261b8-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id 1dee8cd2ebc3141028f80863452f1b396f05bf701ba25c5298f4ca7bacb02313&#xA;Mar 21 11:50:36.076: INFO: At 2017-03-21 11:50:33 +0000 UTC - event for pod-93e261b8-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Started: Started container with id 1dee8cd2ebc3141028f80863452f1b396f05bf701ba25c5298f4ca7bacb02313&#xA;Mar 21 11:50:36.079: INFO: POD                                                         NODE        PHASE    GRACE  CONDITIONS&#xA;Mar 21 11:50:36.079: INFO: pod-projected-secrets-97fe0c6f-0e2c-11e7-9911-42010a8c0008  frakti-e2e  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:50:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:50:34 +0000 UTC ContainersNotReady containers with unready status: [projected-secret-volume-test]}]&#xA;Mar 21 11:50:36.079: INFO: &#xA;Mar 21 11:50:36.080: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 11:50:36.081: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:2704,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 11:50:28 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 11:50:28 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 11:50:28 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 11:50:28 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 11:50:36.082: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 11:50:36.082: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 11:50:36.084: INFO: pod-projected-secrets-97fe0c6f-0e2c-11e7-9911-42010a8c0008 started at 2017-03-21 11:50:34 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 11:50:36.084: INFO: &#x9;Container projected-secret-volume-test ready: false, restart count 0&#xA;Mar 21 11:50:36.154: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 11:50:36.154: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m5.389128s}&#xA;Mar 21 11:50:36.154: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m5.314164s}&#xA;Mar 21 11:50:36.154: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.5 Latency:2m1.113601s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 11:50:36.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-emptydir-vl9r1&#34; for this suite.&#xA;Mar 21 11:50:46.181: INFO: namespace: e2e-tests-emptydir-vl9r1, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Projected should be consumable from pods in volume with mappings as non-root [Conformance] [Volume]" classname="E2eNode Suite" time="18.080845632"></testcase>
      <testcase name="[k8s.io] Container Runtime Conformance Test container runtime conformance blackbox test when starting a container that exits it should run with the expected status [Conformance]" classname="E2eNode Suite" time="33.189098806">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/runtime_conformance_test.go:130&#xA;Expected&#xA;    &lt;bool&gt;: false&#xA;to equal&#xA;    &lt;bool&gt;: true&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/runtime_conformance_test.go:118</failure>
          <system-out>[BeforeEach] [k8s.io] Container Runtime Conformance Test&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 11:51:04.282: INFO: Skipping waiting for service account&#xA;[It] it should run with the expected status [Conformance]&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/runtime_conformance_test.go:130&#xA;�[1mSTEP�[0m: it should get the expected &#39;RestartCount&#39;&#xA;�[1mSTEP�[0m: it should get the expected &#39;Phase&#39;&#xA;�[1mSTEP�[0m: it should get the expected &#39;Ready&#39; condition&#xA;[AfterEach] [k8s.io] Container Runtime Conformance Test&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-runtime-conformance-fr1t1&#34;.&#xA;�[1mSTEP�[0m: Found 10 events.&#xA;Mar 21 11:51:27.345: INFO: At 2017-03-21 11:51:09 +0000 UTC - event for terminate-cmd-rpaa97aaada-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 11:51:27.345: INFO: At 2017-03-21 11:51:09 +0000 UTC - event for terminate-cmd-rpaa97aaada-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id 0630d9c61f37366c47ffe34ca66aef7549e8fe25e5476f3aa66a81e371ad4c21&#xA;Mar 21 11:51:27.345: INFO: At 2017-03-21 11:51:09 +0000 UTC - event for terminate-cmd-rpaa97aaada-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Started: Started container with id 0630d9c61f37366c47ffe34ca66aef7549e8fe25e5476f3aa66a81e371ad4c21&#xA;Mar 21 11:51:27.345: INFO: At 2017-03-21 11:51:11 +0000 UTC - event for terminate-cmd-rpaa97aaada-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id fd592723533ae83fdc507e0311d89446485d22603ff4a0487472d7472c440535&#xA;Mar 21 11:51:27.345: INFO: At 2017-03-21 11:51:11 +0000 UTC - event for terminate-cmd-rpaa97aaada-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Started: Started container with id fd592723533ae83fdc507e0311d89446485d22603ff4a0487472d7472c440535&#xA;Mar 21 11:51:27.345: INFO: At 2017-03-21 11:51:12 +0000 UTC - event for terminate-cmd-rpaa97aaada-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} BackOff: Back-off restarting failed container&#xA;Mar 21 11:51:27.345: INFO: At 2017-03-21 11:51:12 +0000 UTC - event for terminate-cmd-rpaa97aaada-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;terminate-cmd-rpa&#34; with CrashLoopBackOff: &#34;Back-off 10s restarting failed container=terminate-cmd-rpa pod=terminate-cmd-rpaa97aaada-0e2c-11e7-8677-42010a8c0008_e2e-tests-runtime-conformance-fr1t1(a97ac0ca-0e2c-11e7-a3dc-42010a8c0008)&#34;&#xA;&#xA;Mar 21 11:51:27.345: INFO: At 2017-03-21 11:51:25 +0000 UTC - event for terminate-cmd-rpaa97aaada-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id a8f7b2b8270cd453208e3518238c805ad4db6abe94435227497b4d18cd5a4b5f&#xA;Mar 21 11:51:27.345: INFO: At 2017-03-21 11:51:26 +0000 UTC - event for terminate-cmd-rpaa97aaada-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Started: Started container with id a8f7b2b8270cd453208e3518238c805ad4db6abe94435227497b4d18cd5a4b5f&#xA;Mar 21 11:51:27.345: INFO: At 2017-03-21 11:51:26 +0000 UTC - event for terminate-cmd-rpaa97aaada-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;terminate-cmd-rpa&#34; with CrashLoopBackOff: &#34;Back-off 20s restarting failed container=terminate-cmd-rpa pod=terminate-cmd-rpaa97aaada-0e2c-11e7-8677-42010a8c0008_e2e-tests-runtime-conformance-fr1t1(a97ac0ca-0e2c-11e7-a3dc-42010a8c0008)&#34;&#xA;&#xA;Mar 21 11:51:27.348: INFO: POD  NODE  PHASE  GRACE  CONDITIONS&#xA;Mar 21 11:51:27.348: INFO: &#xA;Mar 21 11:51:27.349: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 11:51:27.350: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:2801,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 11:51:18 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 11:51:18 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 11:51:18 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 11:51:18 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 11:51:27.351: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 11:51:27.351: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 11:51:27.421: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 11:51:27.421: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m5.389128s}&#xA;Mar 21 11:51:27.421: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m5.314164s}&#xA;Mar 21 11:51:27.421: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.5 Latency:2m1.108155s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 11:51:27.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-runtime-conformance-fr1t1&#34; for this suite.&#xA;Mar 21 11:51:37.445: INFO: namespace: e2e-tests-runtime-conformance-fr1t1, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook when it is http hook should execute poststart http hook properly [Conformance]" classname="E2eNode Suite" time="50.079491947"></testcase>
      <testcase name="[k8s.io] Pods should have their auto-restart back-off timer reset on image update [Slow]" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] AllocatableEviction [Slow] [Serial] [Disruptive] [Flaky] when we run containers that should cause Memory Pressure should eventually see Memory Pressure, and then evict all of the correct pods" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Kubelet Volume Manager Volume Manager On terminatation of pod with memory backed volume should remove the volume from the node" classname="E2eNode Suite" time="16.139296889">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/volume_manager_test.go:125&#xA;Expected error:&#xA;    &lt;*errors.errorString | 0xc42048b140&gt;: {&#xA;        s: &#34;pod \&#34;poddb1e3bb1-0e2c-11e7-8677-42010a8c0008\&#34; failed with status: {Phase:Failed Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 11:52:27 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 11:52:27 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [containerdb1e3bdd-0e2c-11e7-8677-42010a8c0008]}] Message: Reason: HostIP:10.140.0.8 PodIP:10.10.1.199 StartTime:2017-03-21 11:52:27 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:containerdb1e3bdd-0e2c-11e7-8677-42010a8c0008 State:{Waiting:nil Running:nil Terminated:&amp;ContainerStateTerminated{ExitCode:127,Signal:0,Reason:Failed,Message:,StartedAt:0001-01-01 00:00:00 +0000 UTC,FinishedAt:2017-03-21 11:52:33 +0000 UTC,ContainerID:hyper://e28c12bfcb3d095286573306f41bfd2f254f59ab127a3a5564a6c05a9631c754,}} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff ImageID:sha256:0cb40641836c461bc97c793971d84d758371ed682042457523e4ae701efe7ec9 ContainerID:hyper://e28c12bfcb3d095286573306f41bfd2f254f59ab127a3a5564a6c05a9631c754}] QOSClass:BestEffort}&#34;,&#xA;    }&#xA;    pod &#34;poddb1e3bb1-0e2c-11e7-8677-42010a8c0008&#34; failed with status: {Phase:Failed Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 11:52:27 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 11:52:27 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [containerdb1e3bdd-0e2c-11e7-8677-42010a8c0008]}] Message: Reason: HostIP:10.140.0.8 PodIP:10.10.1.199 StartTime:2017-03-21 11:52:27 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:containerdb1e3bdd-0e2c-11e7-8677-42010a8c0008 State:{Waiting:nil Running:nil Terminated:&amp;ContainerStateTerminated{ExitCode:127,Signal:0,Reason:Failed,Message:,StartedAt:0001-01-01 00:00:00 +0000 UTC,FinishedAt:2017-03-21 11:52:33 +0000 UTC,ContainerID:hyper://e28c12bfcb3d095286573306f41bfd2f254f59ab127a3a5564a6c05a9631c754,}} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff ImageID:sha256:0cb40641836c461bc97c793971d84d758371ed682042457523e4ae701efe7ec9 ContainerID:hyper://e28c12bfcb3d095286573306f41bfd2f254f59ab127a3a5564a6c05a9631c754}] QOSClass:BestEffort}&#xA;not to have occurred&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/volume_manager_test.go:75</failure>
          <system-out>[BeforeEach] [k8s.io] Kubelet Volume Manager&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 11:52:27.563: INFO: Skipping waiting for service account&#xA;[It] should remove the volume from the node&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/volume_manager_test.go:125&#xA;�[1mSTEP�[0m: Creating a pod with a memory backed volume that exits success without restart&#xA;Mar 21 11:52:27.565: INFO: Waiting up to 5m0s for pod poddb1e3bb1-0e2c-11e7-8677-42010a8c0008 status to be success or failure&#xA;Mar 21 11:52:27.567: INFO: Waiting for pod poddb1e3bb1-0e2c-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-kubelet-volume-manager-czxbw&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (2.332006ms elapsed)&#xA;Mar 21 11:52:29.569: INFO: Waiting for pod poddb1e3bb1-0e2c-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-kubelet-volume-manager-czxbw&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (2.004214815s elapsed)&#xA;Mar 21 11:52:31.571: INFO: Waiting for pod poddb1e3bb1-0e2c-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-kubelet-volume-manager-czxbw&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (4.006094968s elapsed)&#xA;[AfterEach] [k8s.io] Kubelet Volume Manager&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-kubelet-volume-manager-czxbw&#34;.&#xA;�[1mSTEP�[0m: Found 3 events.&#xA;Mar 21 11:52:33.577: INFO: At 2017-03-21 11:52:32 +0000 UTC - event for poddb1e3bb1-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 11:52:33.577: INFO: At 2017-03-21 11:52:32 +0000 UTC - event for poddb1e3bb1-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id e28c12bfcb3d095286573306f41bfd2f254f59ab127a3a5564a6c05a9631c754&#xA;Mar 21 11:52:33.577: INFO: At 2017-03-21 11:52:32 +0000 UTC - event for poddb1e3bb1-0e2c-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Started: Started container with id e28c12bfcb3d095286573306f41bfd2f254f59ab127a3a5564a6c05a9631c754&#xA;Mar 21 11:52:33.580: INFO: POD                                      NODE        PHASE   GRACE  CONDITIONS&#xA;Mar 21 11:52:33.580: INFO: poddb1e3bb1-0e2c-11e7-8677-42010a8c0008  frakti-e2e  Failed         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:52:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:52:27 +0000 UTC ContainersNotReady containers with unready status: [containerdb1e3bdd-0e2c-11e7-8677-42010a8c0008]}]&#xA;Mar 21 11:52:33.580: INFO: &#xA;Mar 21 11:52:33.582: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 11:52:33.583: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:2942,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 11:52:28 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 11:52:28 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 11:52:28 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 11:52:28 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 11:52:33.584: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 11:52:33.585: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 11:52:33.587: INFO: poddb1e3bb1-0e2c-11e7-8677-42010a8c0008 started at 2017-03-21 11:52:27 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 11:52:33.587: INFO: &#x9;Container containerdb1e3bdd-0e2c-11e7-8677-42010a8c0008 ready: false, restart count 0&#xA;Mar 21 11:52:33.655: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 11:52:33.655: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m5.455447s}&#xA;Mar 21 11:52:33.655: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m5.389128s}&#xA;Mar 21 11:52:33.655: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.5 Latency:2m1.113601s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 11:52:33.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-kubelet-volume-manager-czxbw&#34; for this suite.&#xA;Mar 21 11:52:43.678: INFO: namespace: e2e-tests-kubelet-volume-manager-czxbw, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Resource-usage [Serial] [Slow] regular resource usage tracking resource tracking for 10 pods per node" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Density [Serial] [Slow] create a batch of pods latency/resource should be within limit when create 10 pods with 0s interval" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] EmptyDir volumes should support (root,0666,tmpfs) [Conformance] [Volume]" classname="E2eNode Suite" time="18.071146433"></testcase>
      <testcase name="[k8s.io] Projected should be consumable from pods in volume with mappings and Item mode set[Conformance] [Volume]" classname="E2eNode Suite" time="18.077490143"></testcase>
      <testcase name="[k8s.io] Sysctls should reject invalid sysctls" classname="E2eNode Suite" time="15.043030279"></testcase>
      <testcase name="[k8s.io] DynamicKubeletConfiguration [Feature:DynamicKubeletConfig] [Serial] [Disruptive] When a configmap called `kubelet-{node-name}` is added to the `kube-system` namespace The Kubelet on that node should restart to take up the new config" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Projected should provide container&#39;s memory limit [Conformance] [Volume]" classname="E2eNode Suite" time="18.06674769"></testcase>
      <testcase name="[k8s.io] Secrets should be consumable from pods in volume [Conformance] [Volume]" classname="E2eNode Suite" time="18.067534764"></testcase>
      <testcase name="[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an error terminated reason" classname="E2eNode Suite" time="70.125829073">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/kubelet_test.go:112&#xA;Timed out after 60.000s.&#xA;Expected&#xA;    &lt;*errors.errorString | 0xc4213fa550&gt;: {&#xA;        s: &#34;expected terminated state reason to be error. Got &amp;ContainerStateTerminated{ExitCode:1,Signal:0,Reason:Failed,Message:,StartedAt:0001-01-01 00:00:00 +0000 UTC,FinishedAt:2017-03-21 11:54:16 +0000 UTC,ContainerID:hyper://e486aa4982295c76fcac1cbf2132c96192a7c67516e50e28663a10beb3f1fd10,}&#34;,&#xA;    }&#xA;to be nil&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/kubelet_test.go:111</failure>
          <system-out>[BeforeEach] [k8s.io] Kubelet&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 11:54:11.038: INFO: Skipping waiting for service account&#xA;[BeforeEach] [k8s.io] Kubelet&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/kubelet_test.go:38&#xA;[BeforeEach] when scheduling a busybox command that always fails in a pod&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/kubelet_test.go:92&#xA;[It] should have an error terminated reason&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/kubelet_test.go:112&#xA;[AfterEach] [k8s.io] Kubelet&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-kubelet-test-mhhqr&#34;.&#xA;�[1mSTEP�[0m: Found 3 events.&#xA;Mar 21 11:55:11.042: INFO: At 2017-03-21 11:54:15 +0000 UTC - event for bin-false18cb5bd1-0e2d-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 11:55:11.042: INFO: At 2017-03-21 11:54:15 +0000 UTC - event for bin-false18cb5bd1-0e2d-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id e486aa4982295c76fcac1cbf2132c96192a7c67516e50e28663a10beb3f1fd10&#xA;Mar 21 11:55:11.042: INFO: At 2017-03-21 11:54:16 +0000 UTC - event for bin-false18cb5bd1-0e2d-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Started: Started container with id e486aa4982295c76fcac1cbf2132c96192a7c67516e50e28663a10beb3f1fd10&#xA;Mar 21 11:55:11.046: INFO: POD                                            NODE        PHASE    GRACE  CONDITIONS&#xA;Mar 21 11:55:11.046: INFO: pod-handle-http-request                        frakti-e2e  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:54:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:54:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:54:57 +0000 UTC  }]&#xA;Mar 21 11:55:11.046: INFO: pod-with-prestop-http-hook                     frakti-e2e  Running  15s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:54:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:55:08 +0000 UTC ContainersNotReady containers with unready status: [pod-with-prestop-http-hook]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:55:05 +0000 UTC  }]&#xA;Mar 21 11:55:11.046: INFO: bin-false18cb5bd1-0e2d-11e7-8677-42010a8c0008  frakti-e2e  Failed          [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:54:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:54:11 +0000 UTC ContainersNotReady containers with unready status: [bin-false18cb5bd1-0e2d-11e7-8677-42010a8c0008]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 11:54:16 +0000 UTC  }]&#xA;Mar 21 11:55:11.046: INFO: &#xA;Mar 21 11:55:11.047: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 11:55:11.049: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:3216,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 11:55:09 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 11:55:09 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 11:55:09 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 11:55:09 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 11:55:11.049: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 11:55:11.050: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 11:55:11.052: INFO: bin-false18cb5bd1-0e2d-11e7-8677-42010a8c0008 started at 2017-03-21 11:54:11 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 11:55:11.052: INFO: &#x9;Container bin-false18cb5bd1-0e2d-11e7-8677-42010a8c0008 ready: false, restart count 0&#xA;Mar 21 11:55:11.052: INFO: pod-with-prestop-http-hook started at 2017-03-21 11:54:59 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 11:55:11.052: INFO: &#x9;Container pod-with-prestop-http-hook ready: false, restart count 0&#xA;Mar 21 11:55:11.052: INFO: pod-handle-http-request started at 2017-03-21 11:54:51 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 11:55:11.052: INFO: &#x9;Container pod-handle-http-request ready: true, restart count 0&#xA;Mar 21 11:55:11.118: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 11:55:11.118: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m5.650748s}&#xA;Mar 21 11:55:11.118: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m5.446661s}&#xA;Mar 21 11:55:11.118: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.5 Latency:2m1.115519s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 11:55:11.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-kubelet-test-mhhqr&#34; for this suite.&#xA;Mar 21 11:55:21.140: INFO: namespace: e2e-tests-kubelet-test-mhhqr, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Container Manager Misc [Serial] Validate OOM score adjustments once the node is setup  pod infra containers oom-score-adj should be -998 and best effort container&#39;s should be 1000" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Downward API volume should set mode on item file [Conformance] [Volume]" classname="E2eNode Suite" time="18.063925547"></testcase>
      <testcase name="[k8s.io] Density [Serial] [Slow] create a batch of pods latency/resource should be within limit when create 105 pods with 100ms interval [Benchmark]" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] EmptyDir volumes when FSGroup is specified [Feature:FSGroup] volume on default medium should have the correct mode using FSGroup [Volume]" classname="E2eNode Suite" time="18.070798124"></testcase>
      <testcase name="[k8s.io] EmptyDir volumes should support (root,0644,default) [Conformance] [Volume]" classname="E2eNode Suite" time="18.063625643"></testcase>
      <testcase name="[k8s.io] CriticalPod [Serial] [Disruptive] when we need to admit a critical pod should be able to create and delete a critical pod" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] EmptyDir volumes should support (root,0644,tmpfs) [Conformance] [Volume]" classname="E2eNode Suite" time="18.066256491"></testcase>
      <testcase name="[k8s.io] Density [Serial] [Slow] create a batch of pods latency/resource should be within limit when create 35 pods with 300ms interval [Benchmark]" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Docker Containers should be able to override the image&#39;s default commmand (docker entrypoint) [Conformance]" classname="E2eNode Suite" time="18.065466147"></testcase>
      <testcase name="[k8s.io] Docker Containers should use the image defaults if command and args are blank [Conformance]" classname="E2eNode Suite" time="18.065544383"></testcase>
      <testcase name="[k8s.io] Projected should be consumable from pods in volume as non-root with FSGroup [Feature:FSGroup] [Volume]" classname="E2eNode Suite" time="18.067722788"></testcase>
      <testcase name="[k8s.io] Projected should be consumable from pods in volume as non-root [Conformance] [Volume]" classname="E2eNode Suite" time="18.097709714"></testcase>
      <testcase name="[k8s.io] Docker Containers should be able to override the image&#39;s default command and arguments [Conformance]" classname="E2eNode Suite" time="18.070379269"></testcase>
      <testcase name="[k8s.io] Downward API volume should provide podname only [Conformance] [Volume]" classname="E2eNode Suite" time="18.065593439"></testcase>
      <testcase name="[k8s.io] GarbageCollect [Serial] Garbage Collection Test: Many Pods with Many Restarting Containers Should eventually garbage collect containers when we exceed the number of dead containers per container" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Networking [k8s.io] Granular Checks: Pods should function for node-pod communication: http [Conformance]" classname="E2eNode Suite" time="80.243830874"></testcase>
      <testcase name="[k8s.io] Docker Containers should be able to override the image&#39;s default arguments (docker cmd) [Conformance]" classname="E2eNode Suite" time="18.064755859"></testcase>
      <testcase name="[k8s.io] InitContainer should invoke init containers on a RestartNever pod" classname="E2eNode Suite" time="28.104302471"></testcase>
      <testcase name="[k8s.io] Container Manager Misc [Serial] Validate OOM score adjustments once the node is setup Kubelet&#39;s oom-score-adj should be -999" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Projected should be consumable in multiple volumes in the same pod [Conformance] [Volume]" classname="E2eNode Suite" time="18.0594255"></testcase>
      <testcase name="[k8s.io] Kubelet Eviction Manager [Serial] [Disruptive] hard eviction test pod using the most disk space gets evicted when the node disk usage is above the eviction hard threshold should evict the pod using the most disk space [Slow]" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Kubelet when scheduling a read only busybox container it should not write to root filesystem [Conformance]" classname="E2eNode Suite" time="96.111017445">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/kubelet_test.go:152&#xA;Timed out after 60.000s.&#xA;Expected&#xA;    &lt;string&gt;: &#xA;to equal&#xA;    &lt;string&gt;: /bin/sh: can&#39;t create /file: Read-only file system&#xA;    &#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/kubelet_test.go:151</failure>
          <system-out>[BeforeEach] [k8s.io] Kubelet&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 12:00:46.371: INFO: Skipping waiting for service account&#xA;[BeforeEach] [k8s.io] Kubelet&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/kubelet_test.go:38&#xA;[It] it should not write to root filesystem [Conformance]&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/kubelet_test.go:152&#xA;[AfterEach] [k8s.io] Kubelet&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-kubelet-test-5vc89&#34;.&#xA;�[1mSTEP�[0m: Found 3 events.&#xA;Mar 21 12:01:52.378: INFO: At 2017-03-21 12:00:51 +0000 UTC - event for busybox-readonly-fs394dbc27-0e28-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 12:01:52.378: INFO: At 2017-03-21 12:00:51 +0000 UTC - event for busybox-readonly-fs394dbc27-0e28-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id 654181026fb8e077b3b400a03b0e8314c4450d89527996178d636fd1aca8ae0e&#xA;Mar 21 12:01:52.378: INFO: At 2017-03-21 12:00:51 +0000 UTC - event for busybox-readonly-fs394dbc27-0e28-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Started: Started container with id 654181026fb8e077b3b400a03b0e8314c4450d89527996178d636fd1aca8ae0e&#xA;Mar 21 12:01:52.382: INFO: POD                                                      NODE        PHASE    GRACE  CONDITIONS&#xA;Mar 21 12:01:52.382: INFO: busybox-readonly-fs394dbc27-0e28-11e7-8677-42010a8c0008  frakti-e2e  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:00:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:00:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:00:52 +0000 UTC  }]&#xA;Mar 21 12:01:52.382: INFO: &#xA;Mar 21 12:01:52.383: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 12:01:52.385: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:3647,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 12:01:51 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 12:01:51 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 12:01:51 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 12:01:51 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 12:01:52.385: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 12:01:52.385: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 12:01:52.388: INFO: busybox-readonly-fs394dbc27-0e28-11e7-8677-42010a8c0008 started at 2017-03-21 12:00:46 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 12:01:52.388: INFO: &#x9;Container busybox-readonly-fs394dbc27-0e28-11e7-8677-42010a8c0008 ready: true, restart count 0&#xA;Mar 21 12:01:52.444: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 12:01:52.444: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m5.583779s}&#xA;Mar 21 12:01:52.444: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m5.569712s}&#xA;Mar 21 12:01:52.444: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.5 Latency:2m1.167505s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 12:01:52.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-kubelet-test-5vc89&#34; for this suite.&#xA;Mar 21 12:02:22.479: INFO: namespace: e2e-tests-kubelet-test-5vc89, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Downward API volume should provide podname as non-root with fsgroup and defaultMode [Feature:FSGroup] [Volume]" classname="E2eNode Suite" time="18.063576197"></testcase>
      <testcase name="[k8s.io] Container Runtime Conformance Test container runtime conformance blackbox test when running a container with a new image should not be able to pull non-existing image from gcr.io [Conformance]" classname="E2eNode Suite" time="17.061232992"></testcase>
      <testcase name="[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook when it is exec hook should execute poststart exec hook properly [Conformance]" classname="E2eNode Suite" time="26.192728314">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/lifecycle_hook_test.go:94&#xA;Expected error:&#xA;    &lt;*errors.errorString | 0xc4203ec620&gt;: {&#xA;        s: &#34;pod ran to completion&#34;,&#xA;    }&#xA;    pod ran to completion&#xA;not to have occurred&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/pods.go:83</failure>
          <system-out>[BeforeEach] [k8s.io] Container Lifecycle Hook&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 12:02:57.614: INFO: Skipping waiting for service account&#xA;[BeforeEach] when create a pod with lifecycle hook&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/lifecycle_hook_test.go:45&#xA;[BeforeEach] when it is exec hook&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/lifecycle_hook_test.go:74&#xA;[It] should execute poststart exec hook properly [Conformance]&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/lifecycle_hook_test.go:94&#xA;�[1mSTEP�[0m: create the pod with lifecycle hook&#xA;Mar 21 12:03:05.619: INFO: Unexpected error occurred: pod ran to completion&#xA;[AfterEach] when it is exec hook&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/lifecycle_hook_test.go:81&#xA;�[1mSTEP�[0m: cleanup the temporary file created in the test.&#xA;Mar 21 12:03:05.627: INFO: Waiting up to 3m0s for pod pod-clean-up status to be success or failure&#xA;Mar 21 12:03:05.628: INFO: Waiting for pod pod-clean-up in namespace &#39;e2e-tests-container-lifecycle-hook-1dmfc&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (1.39708ms elapsed)&#xA;Mar 21 12:03:07.631: INFO: Waiting for pod pod-clean-up in namespace &#39;e2e-tests-container-lifecycle-hook-1dmfc&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (2.003894104s elapsed)&#xA;Mar 21 12:03:09.633: INFO: Waiting for pod pod-clean-up in namespace &#39;e2e-tests-container-lifecycle-hook-1dmfc&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (4.006105214s elapsed)&#xA;Mar 21 12:03:11.635: INFO: Waiting for pod pod-clean-up in namespace &#39;e2e-tests-container-lifecycle-hook-1dmfc&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (6.00840613s elapsed)&#xA;[AfterEach] [k8s.io] Container Lifecycle Hook&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-container-lifecycle-hook-1dmfc&#34;.&#xA;�[1mSTEP�[0m: Found 9 events.&#xA;Mar 21 12:03:13.643: INFO: At 2017-03-21 12:03:03 +0000 UTC - event for pod-with-poststart-exec-hook: {kubelet frakti-e2e} FailedPostStartHook: &#xA;Mar 21 12:03:13.643: INFO: At 2017-03-21 12:03:03 +0000 UTC - event for pod-with-poststart-exec-hook: {kubelet frakti-e2e} Killing: Killing container with id hyper://9eafdfdb52ecf94fa35f4e1b24266509224076df2d08ab34f3be41f2b74aeb0c:FailedPostStartHook&#xA;Mar 21 12:03:13.643: INFO: At 2017-03-21 12:03:03 +0000 UTC - event for pod-with-poststart-exec-hook: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;pod-with-poststart-exec-hook&#34; with PostStart handler: command &#39;touch /tmp/test-52a87ef3-0e2e-11e7-8677-42010a8c0008&#39; exited with 127: exec failed: No such fil: &#34;PostStart Hook Failed&#34;&#xA;&#xA;Mar 21 12:03:13.643: INFO: At 2017-03-21 12:03:03 +0000 UTC - event for pod-with-poststart-exec-hook: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 12:03:13.643: INFO: At 2017-03-21 12:03:03 +0000 UTC - event for pod-with-poststart-exec-hook: {kubelet frakti-e2e} Created: Created container with id 9eafdfdb52ecf94fa35f4e1b24266509224076df2d08ab34f3be41f2b74aeb0c&#xA;Mar 21 12:03:13.643: INFO: At 2017-03-21 12:03:03 +0000 UTC - event for pod-with-poststart-exec-hook: {kubelet frakti-e2e} Started: Started container with id 9eafdfdb52ecf94fa35f4e1b24266509224076df2d08ab34f3be41f2b74aeb0c&#xA;Mar 21 12:03:13.643: INFO: At 2017-03-21 12:03:11 +0000 UTC - event for pod-clean-up: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 12:03:13.643: INFO: At 2017-03-21 12:03:11 +0000 UTC - event for pod-clean-up: {kubelet frakti-e2e} Created: Created container with id dffb9af84bf5cc7a0348c4089686384ec68ce14cdda49654c56384612ccd7f56&#xA;Mar 21 12:03:13.643: INFO: At 2017-03-21 12:03:11 +0000 UTC - event for pod-clean-up: {kubelet frakti-e2e} Started: Started container with id dffb9af84bf5cc7a0348c4089686384ec68ce14cdda49654c56384612ccd7f56&#xA;Mar 21 12:03:13.648: INFO: POD                           NODE        PHASE   GRACE  CONDITIONS&#xA;Mar 21 12:03:13.648: INFO: pod-clean-up                  frakti-e2e  Failed         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:03:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:03:05 +0000 UTC ContainersNotReady containers with unready status: [pod-clean-up]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:03:12 +0000 UTC  }]&#xA;Mar 21 12:03:13.648: INFO: pod-with-poststart-exec-hook  frakti-e2e  Failed         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:02:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:02:57 +0000 UTC ContainersNotReady containers with unready status: [pod-with-poststart-exec-hook]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:03:04 +0000 UTC  }]&#xA;Mar 21 12:03:13.648: INFO: &#xA;Mar 21 12:03:13.650: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 12:03:13.652: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:3718,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 12:03:11 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 12:03:11 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 12:03:11 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 12:03:11 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 12:03:13.653: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 12:03:13.654: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 12:03:13.657: INFO: pod-with-poststart-exec-hook started at 2017-03-21 12:02:57 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 12:03:13.657: INFO: &#x9;Container pod-with-poststart-exec-hook ready: false, restart count 0&#xA;Mar 21 12:03:13.657: INFO: pod-clean-up started at 2017-03-21 12:03:05 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 12:03:13.657: INFO: &#x9;Container pod-clean-up ready: false, restart count 0&#xA;Mar 21 12:03:13.768: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 12:03:13.768: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m5.583779s}&#xA;Mar 21 12:03:13.768: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m5.569712s}&#xA;Mar 21 12:03:13.768: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.5 Latency:2m1.160383s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 12:03:13.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-container-lifecycle-hook-1dmfc&#34; for this suite.&#xA;Mar 21 12:03:23.786: INFO: namespace: e2e-tests-container-lifecycle-hook-1dmfc, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [Conformance] [Volume]" classname="E2eNode Suite" time="18.061277459"></testcase>
      <testcase name="[k8s.io] Variable Expansion should allow composing env vars into new env vars [Conformance]" classname="E2eNode Suite" time="18.138227787">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/expansion.go:71&#xA;Expected error:&#xA;    &lt;*errors.errorString | 0xc42071ae60&gt;: {&#xA;        s: &#34;expected pod \&#34;var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008\&#34; success: &lt;nil&gt;&#34;,&#xA;    }&#xA;    expected pod &#34;var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008&#34; success: &lt;nil&gt;&#xA;not to have occurred&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:2197</failure>
          <system-out>[BeforeEach] [k8s.io] Variable Expansion&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 12:03:41.873: INFO: Skipping waiting for service account&#xA;[It] should allow composing env vars into new env vars [Conformance]&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/expansion.go:71&#xA;�[1mSTEP�[0m: Creating a pod to test env composition&#xA;Mar 21 12:03:41.875: INFO: Waiting up to 5m0s for pod var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008 status to be success or failure&#xA;Mar 21 12:03:41.877: INFO: Waiting for pod var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-var-expansion-xvgw8&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (2.18119ms elapsed)&#xA;Mar 21 12:03:43.878: INFO: Waiting for pod var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-var-expansion-xvgw8&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (2.003930659s elapsed)&#xA;Mar 21 12:03:45.880: INFO: Waiting for pod var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-var-expansion-xvgw8&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (4.00568707s elapsed)&#xA;Mar 21 12:03:47.882: INFO: Waiting for pod var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-var-expansion-xvgw8&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (6.007673145s elapsed)&#xA;Mar 21 12:03:49.890: INFO: Output of node &#34;frakti-e2e&#34; pod &#34;var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008&#34; container &#34;dapi-container&#34;: exec failed: No such file or directory&#xA;&#xA;�[1mSTEP�[0m: delete the pod&#xA;Mar 21 12:03:49.895: INFO: Waiting for pod var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008 to disappear&#xA;Mar 21 12:03:49.896: INFO: Pod var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008 no longer exists&#xA;Mar 21 12:03:49.896: INFO: Unexpected error occurred: expected pod &#34;var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008&#34; success: &lt;nil&gt;&#xA;[AfterEach] [k8s.io] Variable Expansion&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-var-expansion-xvgw8&#34;.&#xA;�[1mSTEP�[0m: Found 3 events.&#xA;Mar 21 12:03:49.898: INFO: At 2017-03-21 12:03:46 +0000 UTC - event for var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 12:03:49.898: INFO: At 2017-03-21 12:03:47 +0000 UTC - event for var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id bdae070ab4455d48a372864b625e3d08ade0b1c8556e677efb17bf62201ad54a&#xA;Mar 21 12:03:49.898: INFO: At 2017-03-21 12:03:47 +0000 UTC - event for var-expansion-6d09d68e-0e2e-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Started: Started container with id bdae070ab4455d48a372864b625e3d08ade0b1c8556e677efb17bf62201ad54a&#xA;Mar 21 12:03:49.901: INFO: POD  NODE  PHASE  GRACE  CONDITIONS&#xA;Mar 21 12:03:49.901: INFO: &#xA;Mar 21 12:03:49.902: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 12:03:49.904: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:3760,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 12:03:41 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 12:03:41 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 12:03:41 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 12:03:41 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 12:03:49.904: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 12:03:49.905: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 12:03:49.971: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 12:03:49.971: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m5.583779s}&#xA;Mar 21 12:03:49.971: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m5.569712s}&#xA;Mar 21 12:03:49.971: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.5 Latency:2m1.160383s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 12:03:49.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-var-expansion-xvgw8&#34; for this suite.&#xA;Mar 21 12:03:59.990: INFO: namespace: e2e-tests-var-expansion-xvgw8, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Projected optional updates should be reflected in volume [Conformance] [Volume]" classname="E2eNode Suite" time="112.33107083"></testcase>
      <testcase name="[k8s.io] Secrets should be consumable from pods in volume with mappings and Item Mode set [Conformance] [Volume]" classname="E2eNode Suite" time="18.070442291"></testcase>
      <testcase name="[k8s.io] Projected should update labels on modification [Conformance] [Volume]" classname="E2eNode Suite" time="42.579326568"></testcase>
      <testcase name="[k8s.io] ContainerLogPath Pod with a container printed log to stdout should print log to correct log path" classname="E2eNode Suite" time="18.128813873">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/log_path_test.go:117&#xA;Failed waiting for pod: logger-pod to enter success state&#xA;Expected error:&#xA;    &lt;*errors.errorString | 0xc4214df190&gt;: {&#xA;        s: &#34;pod \&#34;logger-pod\&#34; failed with status: {Phase:Failed Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:06:53 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:06:53 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [logger-container]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:06:59 +0000 UTC Reason: Message:}] Message: Reason: HostIP:10.140.0.8 PodIP: StartTime:2017-03-21 12:06:53 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:logger-container State:{Waiting:nil Running:nil Terminated:&amp;ContainerStateTerminated{ExitCode:127,Signal:0,Reason:Failed,Message:,StartedAt:0001-01-01 00:00:00 +0000 UTC,FinishedAt:2017-03-21 12:06:58 +0000 UTC,ContainerID:hyper://7b9619618d1453171a4d00f98557c9388671a06f77174061b6b4f4b9a3a3240e,}} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff ImageID:sha256:0cb40641836c461bc97c793971d84d758371ed682042457523e4ae701efe7ec9 ContainerID:hyper://7b9619618d1453171a4d00f98557c9388671a06f77174061b6b4f4b9a3a3240e}] QOSClass:BestEffort}&#34;,&#xA;    }&#xA;    pod &#34;logger-pod&#34; failed with status: {Phase:Failed Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:06:53 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:06:53 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [logger-container]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:06:59 +0000 UTC Reason: Message:}] Message: Reason: HostIP:10.140.0.8 PodIP: StartTime:2017-03-21 12:06:53 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:logger-container State:{Waiting:nil Running:nil Terminated:&amp;ContainerStateTerminated{ExitCode:127,Signal:0,Reason:Failed,Message:,StartedAt:0001-01-01 00:00:00 +0000 UTC,FinishedAt:2017-03-21 12:06:58 +0000 UTC,ContainerID:hyper://7b9619618d1453171a4d00f98557c9388671a06f77174061b6b4f4b9a3a3240e,}} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff ImageID:sha256:0cb40641836c461bc97c793971d84d758371ed682042457523e4ae701efe7ec9 ContainerID:hyper://7b9619618d1453171a4d00f98557c9388671a06f77174061b6b4f4b9a3a3240e}] QOSClass:BestEffort}&#xA;not to have occurred&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/log_path_test.go:68</failure>
          <system-out>[BeforeEach] [k8s.io] ContainerLogPath&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 12:06:53.003: INFO: Skipping waiting for service account&#xA;[It] should print log to correct log path&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/log_path_test.go:117&#xA;Mar 21 12:06:53.005: INFO: Waiting up to 5m0s for pod logger-pod status to be success or failure&#xA;Mar 21 12:06:53.007: INFO: Waiting for pod logger-pod in namespace &#39;e2e-tests-kubelet-container-log-path-lld2l&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (1.861472ms elapsed)&#xA;Mar 21 12:06:55.009: INFO: Waiting for pod logger-pod in namespace &#39;e2e-tests-kubelet-container-log-path-lld2l&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (2.003855695s elapsed)&#xA;Mar 21 12:06:57.011: INFO: Waiting for pod logger-pod in namespace &#39;e2e-tests-kubelet-container-log-path-lld2l&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (4.005783676s elapsed)&#xA;Mar 21 12:06:59.013: INFO: Waiting for pod logger-pod in namespace &#39;e2e-tests-kubelet-container-log-path-lld2l&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (6.007696903s elapsed)&#xA;Mar 21 12:07:01.015: INFO: Unexpected error occurred: pod &#34;logger-pod&#34; failed with status: {Phase:Failed Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:06:53 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:06:53 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [logger-container]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:06:59 +0000 UTC Reason: Message:}] Message: Reason: HostIP:10.140.0.8 PodIP: StartTime:2017-03-21 12:06:53 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:logger-container State:{Waiting:nil Running:nil Terminated:&amp;ContainerStateTerminated{ExitCode:127,Signal:0,Reason:Failed,Message:,StartedAt:0001-01-01 00:00:00 +0000 UTC,FinishedAt:2017-03-21 12:06:58 +0000 UTC,ContainerID:hyper://7b9619618d1453171a4d00f98557c9388671a06f77174061b6b4f4b9a3a3240e,}} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff ImageID:sha256:0cb40641836c461bc97c793971d84d758371ed682042457523e4ae701efe7ec9 ContainerID:hyper://7b9619618d1453171a4d00f98557c9388671a06f77174061b6b4f4b9a3a3240e}] QOSClass:BestEffort}&#xA;[AfterEach] [k8s.io] ContainerLogPath&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-kubelet-container-log-path-lld2l&#34;.&#xA;�[1mSTEP�[0m: Found 3 events.&#xA;Mar 21 12:07:01.017: INFO: At 2017-03-21 12:06:58 +0000 UTC - event for logger-pod: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 12:07:01.017: INFO: At 2017-03-21 12:06:58 +0000 UTC - event for logger-pod: {kubelet frakti-e2e} Created: Created container with id 7b9619618d1453171a4d00f98557c9388671a06f77174061b6b4f4b9a3a3240e&#xA;Mar 21 12:07:01.017: INFO: At 2017-03-21 12:06:58 +0000 UTC - event for logger-pod: {kubelet frakti-e2e} Started: Started container with id 7b9619618d1453171a4d00f98557c9388671a06f77174061b6b4f4b9a3a3240e&#xA;Mar 21 12:07:01.021: INFO: POD         NODE        PHASE   GRACE  CONDITIONS&#xA;Mar 21 12:07:01.021: INFO: logger-pod  frakti-e2e  Failed         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:06:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:06:53 +0000 UTC ContainersNotReady containers with unready status: [logger-container]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:06:59 +0000 UTC  }]&#xA;Mar 21 12:07:01.021: INFO: &#xA;Mar 21 12:07:01.022: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 12:07:01.024: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:3877,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 12:06:52 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 12:06:52 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 12:06:52 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 12:06:52 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 12:07:01.024: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 12:07:01.025: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 12:07:01.028: INFO: logger-pod started at 2017-03-21 12:06:53 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 12:07:01.028: INFO: &#x9;Container logger-container ready: false, restart count 0&#xA;Mar 21 12:07:01.087: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 12:07:01.087: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m5.55315s}&#xA;Mar 21 12:07:01.087: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m5.55315s}&#xA;Mar 21 12:07:01.087: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.5 Latency:2m1.16022s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 12:07:01.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-kubelet-container-log-path-lld2l&#34; for this suite.&#xA;Mar 21 12:07:11.106: INFO: namespace: e2e-tests-kubelet-container-log-path-lld2l, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Summary API when querying /stats/summary should report resource usage through the stats api" classname="E2eNode Suite" time="113.147258873">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/summary_test.go:258&#xA;Timed out after 60.000s.&#xA;Error: Unexpected non-nil/non-zero extra argument at index 1:&#xA;&#x9;&lt;*errors.errorString&gt;: &amp;errors.errorString{s:&#34;failed to parse /stats/summary to go struct: &amp;{Status:500 Internal Server Error StatusCode:500 Proto:HTTP/1.1 ProtoMajor:1 ProtoMinor:1 Header:map[Date:[Tue, 21 Mar 2017 12:08:19 GMT] Content-Length:[80] Content-Type:[text/plain; charset=utf-8]] Body:0xc4200e5940 ContentLength:80 TransferEncoding:[] Close:false Uncompressed:false Trailer:map[] Request:0xc4213e20f0 TLS:&lt;nil&gt;}&#34;}&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/summary_test.go:255</failure>
          <system-out>[BeforeEach] [k8s.io] Summary API&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 12:07:11.135: INFO: Skipping waiting for service account&#xA;[It] should report resource usage through the stats api&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/summary_test.go:258&#xA;�[1mSTEP�[0m: Creating test pods&#xA;�[1mSTEP�[0m: Validating /stats/summary&#xA;[AfterEach] when querying /stats/summary&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/summary_test.go:50&#xA;Mar 21 12:08:34.155: INFO: Running kubectl logs on non-ready containers in e2e-tests-summary-test-j4pc6&#xA;�[1mSTEP�[0m: Logs of e2e-tests-summary-test-j4pc6/stats-busybox-0:busybox-container on node frakti-e2e&#xA;Mar 21 12:08:34.159: INFO:  : STARTLOG&#xA;exec failed: No such file or directory&#xA;&#xA;ENDLOG for container e2e-tests-summary-test-j4pc6:stats-busybox-0:busybox-container&#xA;�[1mSTEP�[0m: Logs of e2e-tests-summary-test-j4pc6/stats-busybox-1:busybox-container on node frakti-e2e&#xA;Mar 21 12:08:34.162: INFO:  : STARTLOG&#xA;exec failed: No such file or directory&#xA;&#xA;ENDLOG for container e2e-tests-summary-test-j4pc6:stats-busybox-1:busybox-container&#xA;�[1mSTEP�[0m: Recording processes in system cgroups&#xA;Mar 21 12:08:34.164: INFO: Processes in kubelet cgroup (/kubelet.slice):&#xA;Mar 21 12:08:34.166: INFO:   /root/go-project/src/k8s.io/kubernetes/_output/local/go/bin/kubelet�--kubelet-cgroups=/kubelet.slice�--cgroup-root=/�--api-servers�http://localhost:8080�--address�0.0.0.0�--port�10250�--read-only-port�10255�--volume-stats-agg-period�10s�--allow-privileged�true�--serialize-image-pulls�false�--pod-manifest-path�/root/go-project/src/k8s.io/kubernetes/_output/local/go/bin/pod-manifest759017233�--file-check-frequency�10s�--pod-cidr�10.180.0.0/24�--eviction-pressure-transition-period�30s�--feature-gates��--eviction-hard�memory.available&lt;250Mi,nodefs.available&lt;10%,nodefs.inodesFree&lt;5%�--eviction-minimum-reclaim�nodefs.available=5%,nodefs.inodesFree=5%�--v�4�--logtostderr�--network-plugin=kubenet�--network-plugin-dir�/root/go-project/src/k8s.io/kubernetes/_output/local/go/bin/cni/bin�--hostname-override�frakti-e2e�--container-runtime=docker�--network-plugin=�--network-plugin-dir=�--container-runtime=remote�--container-runtime-endpoint=/var/run/frakti.sock�--feature-gates=AllAlpha=true,Accelerators=false�&#xA;Mar 21 12:08:34.166: INFO:   journalctl�-k�-f�&#xA;Mar 21 12:08:34.166: INFO: Skipping unconfigured cgroup runtime&#xA;Mar 21 12:08:34.166: INFO: Skipping unconfigured cgroup misc&#xA;[AfterEach] [k8s.io] Summary API&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-summary-test-j4pc6&#34;.&#xA;�[1mSTEP�[0m: Found 28 events.&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:17 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:17 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} Created: Created container with id 66d3ba45b30c8452061444d679460b45c8fa49f27d49c979771b3afa9ca72a7d&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:17 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} Started: Started container with id 66d3ba45b30c8452061444d679460b45c8fa49f27d49c979771b3afa9ca72a7d&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:17 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:18 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} Started: Started container with id a87d86a4f2f0b01cffdfae2f67e8594da61a5bfc3aaa8f3f4a1755b72d19317b&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:18 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} Created: Created container with id a87d86a4f2f0b01cffdfae2f67e8594da61a5bfc3aaa8f3f4a1755b72d19317b&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:19 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} Created: Created container with id ce3dee232990e104b4cab4c00187db1c2f0c3f45e7c6da0ac966b5592fa42846&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:19 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} Started: Started container with id ce3dee232990e104b4cab4c00187db1c2f0c3f45e7c6da0ac966b5592fa42846&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:19 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} Started: Started container with id 7a6bcb7400b86f09793607b25f32bd30a2f5456a5d8dc81031bd983ef35dba08&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:19 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} Created: Created container with id 7a6bcb7400b86f09793607b25f32bd30a2f5456a5d8dc81031bd983ef35dba08&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:20 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} BackOff: Back-off restarting failed container&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:20 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;busybox-container&#34; with CrashLoopBackOff: &#34;Back-off 10s restarting failed container=busybox-container pod=stats-busybox-0_e2e-tests-summary-test-j4pc6(e9c4e654-0e2e-11e7-a3dc-42010a8c0008)&#34;&#xA;&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:20 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: rpc error: code = 2 desc = Can not find container by name(66d3ba45b30c8452061444d679460b45c8fa49f27d49c979771b3afa9ca72a7d)&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:21 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: rpc error: code = 2 desc = Can not find container by name(a87d86a4f2f0b01cffdfae2f67e8594da61a5bfc3aaa8f3f4a1755b72d19317b)&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:21 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} BackOff: Back-off restarting failed container&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:21 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;busybox-container&#34; with CrashLoopBackOff: &#34;Back-off 10s restarting failed container=busybox-container pod=stats-busybox-1_e2e-tests-summary-test-j4pc6(e9c4c62c-0e2e-11e7-a3dc-42010a8c0008)&#34;&#xA;&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:32 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} Created: Created container with id 74b1f2ae32c4fa159244e1ceae9cda536407d66e7b8ccf58952689906be04b76&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:33 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} Started: Started container with id 74b1f2ae32c4fa159244e1ceae9cda536407d66e7b8ccf58952689906be04b76&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:34 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;busybox-container&#34; with CrashLoopBackOff: &#34;Back-off 20s restarting failed container=busybox-container pod=stats-busybox-0_e2e-tests-summary-test-j4pc6(e9c4e654-0e2e-11e7-a3dc-42010a8c0008)&#34;&#xA;&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:35 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} Created: Created container with id d6c385a33a55566b0f807780537cfb194eb28949cda4b114560d779cb2a5b83a&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:36 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} Started: Started container with id d6c385a33a55566b0f807780537cfb194eb28949cda4b114560d779cb2a5b83a&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:36 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;busybox-container&#34; with CrashLoopBackOff: &#34;Back-off 20s restarting failed container=busybox-container pod=stats-busybox-1_e2e-tests-summary-test-j4pc6(e9c4c62c-0e2e-11e7-a3dc-42010a8c0008)&#34;&#xA;&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:07:59 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} Created: Created container with id c1520c13ce1f42015e1325b1824d9d70ff31fba60749662bbd8e34f75fbae46b&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:08:00 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;busybox-container&#34; with CrashLoopBackOff: &#34;Back-off 40s restarting failed container=busybox-container pod=stats-busybox-0_e2e-tests-summary-test-j4pc6(e9c4e654-0e2e-11e7-a3dc-42010a8c0008)&#34;&#xA;&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:08:00 +0000 UTC - event for stats-busybox-0: {kubelet frakti-e2e} Started: Started container with id c1520c13ce1f42015e1325b1824d9d70ff31fba60749662bbd8e34f75fbae46b&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:08:03 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} Created: Created container with id 8691ba2089a5a47af80f99daaa6b5173f813bb6a9ade7379c2ae4f4a176cb873&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:08:04 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} Started: Started container with id 8691ba2089a5a47af80f99daaa6b5173f813bb6a9ade7379c2ae4f4a176cb873&#xA;Mar 21 12:08:34.170: INFO: At 2017-03-21 12:08:05 +0000 UTC - event for stats-busybox-1: {kubelet frakti-e2e} FailedSync: Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;busybox-container&#34; with CrashLoopBackOff: &#34;Back-off 40s restarting failed container=busybox-container pod=stats-busybox-1_e2e-tests-summary-test-j4pc6(e9c4c62c-0e2e-11e7-a3dc-42010a8c0008)&#34;&#xA;&#xA;Mar 21 12:08:34.174: INFO: POD              NODE        PHASE    GRACE  CONDITIONS&#xA;Mar 21 12:08:34.174: INFO: stats-busybox-0  frakti-e2e  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:07:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:07:11 +0000 UTC ContainersNotReady containers with unready status: [busybox-container]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:07:18 +0000 UTC  }]&#xA;Mar 21 12:08:34.174: INFO: stats-busybox-1  frakti-e2e  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:07:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:07:11 +0000 UTC ContainersNotReady containers with unready status: [busybox-container]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:08:03 +0000 UTC  }]&#xA;Mar 21 12:08:34.174: INFO: &#xA;Mar 21 12:08:34.175: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 12:08:34.176: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:3974,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 12:08:33 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 12:08:33 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 12:08:33 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 12:08:33 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 12:08:34.176: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 12:08:34.177: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 12:08:34.179: INFO: stats-busybox-1 started at 2017-03-21 12:07:11 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 12:08:34.179: INFO: &#x9;Container busybox-container ready: false, restart count 3&#xA;Mar 21 12:08:34.179: INFO: stats-busybox-0 started at 2017-03-21 12:07:11 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 12:08:34.179: INFO: &#x9;Container busybox-container ready: false, restart count 3&#xA;Mar 21 12:08:34.235: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 12:08:34.235: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m5.527231s}&#xA;Mar 21 12:08:34.235: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m1.18373s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 12:08:34.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-summary-test-j4pc6&#34; for this suite.&#xA;Mar 21 12:09:04.263: INFO: namespace: e2e-tests-summary-test-j4pc6, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] ConfigMap should be consumable in multiple volumes in the same pod [Conformance] [Volume]" classname="E2eNode Suite" time="18.071979449"></testcase>
      <testcase name="[k8s.io] Secrets optional updates should be reflected in volume [Conformance] [Volume]" classname="E2eNode Suite" time="27.104496812"></testcase>
      <testcase name="[k8s.io] Networking [k8s.io] Granular Checks: Pods should function for intra-pod communication: udp [Conformance]" classname="E2eNode Suite" time="80.354022474"></testcase>
      <testcase name="[k8s.io] Downward API should provide pod name and namespace as env vars [Conformance]" classname="E2eNode Suite" time="18.161596846">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:63&#xA;Expected error:&#xA;    &lt;*errors.errorString | 0xc4214de8e0&gt;: {&#xA;        s: &#34;expected pod \&#34;downward-api-78097495-0e2f-11e7-8677-42010a8c0008\&#34; success: &lt;nil&gt;&#34;,&#xA;    }&#xA;    expected pod &#34;downward-api-78097495-0e2f-11e7-8677-42010a8c0008&#34; success: &lt;nil&gt;&#xA;not to have occurred&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:2197</failure>
          <system-out>[BeforeEach] [k8s.io] Downward API&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 12:11:09.822: INFO: Skipping waiting for service account&#xA;[It] should provide pod name and namespace as env vars [Conformance]&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:63&#xA;�[1mSTEP�[0m: Creating a pod to test downward api env vars&#xA;Mar 21 12:11:09.824: INFO: Waiting up to 5m0s for pod downward-api-78097495-0e2f-11e7-8677-42010a8c0008 status to be success or failure&#xA;Mar 21 12:11:09.825: INFO: Waiting for pod downward-api-78097495-0e2f-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-downward-api-zzt7k&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (812.437µs elapsed)&#xA;Mar 21 12:11:11.826: INFO: Waiting for pod downward-api-78097495-0e2f-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-downward-api-zzt7k&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (2.002476158s elapsed)&#xA;Mar 21 12:11:13.829: INFO: Waiting for pod downward-api-78097495-0e2f-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-downward-api-zzt7k&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (4.005216811s elapsed)&#xA;Mar 21 12:11:15.833: INFO: Waiting for pod downward-api-78097495-0e2f-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-downward-api-zzt7k&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (6.008686719s elapsed)&#xA;Mar 21 12:11:17.843: INFO: Output of node &#34;frakti-e2e&#34; pod &#34;downward-api-78097495-0e2f-11e7-8677-42010a8c0008&#34; container &#34;dapi-container&#34;: exec failed: No such file or directory&#xA;&#xA;�[1mSTEP�[0m: delete the pod&#xA;Mar 21 12:11:17.849: INFO: Waiting for pod downward-api-78097495-0e2f-11e7-8677-42010a8c0008 to disappear&#xA;Mar 21 12:11:17.853: INFO: Pod downward-api-78097495-0e2f-11e7-8677-42010a8c0008 no longer exists&#xA;Mar 21 12:11:17.853: INFO: Unexpected error occurred: expected pod &#34;downward-api-78097495-0e2f-11e7-8677-42010a8c0008&#34; success: &lt;nil&gt;&#xA;[AfterEach] [k8s.io] Downward API&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-downward-api-zzt7k&#34;.&#xA;�[1mSTEP�[0m: Found 3 events.&#xA;Mar 21 12:11:17.856: INFO: At 2017-03-21 12:11:15 +0000 UTC - event for downward-api-78097495-0e2f-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 12:11:17.856: INFO: At 2017-03-21 12:11:15 +0000 UTC - event for downward-api-78097495-0e2f-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id cb8aac95bbc8dc3d91a659475ba77f3c0a370a00aa4c174179afeb51c31dd840&#xA;Mar 21 12:11:17.856: INFO: At 2017-03-21 12:11:15 +0000 UTC - event for downward-api-78097495-0e2f-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Started: Started container with id cb8aac95bbc8dc3d91a659475ba77f3c0a370a00aa4c174179afeb51c31dd840&#xA;Mar 21 12:11:17.860: INFO: POD  NODE  PHASE  GRACE  CONDITIONS&#xA;Mar 21 12:11:17.860: INFO: &#xA;Mar 21 12:11:17.862: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 12:11:17.863: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:4152,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 12:11:14 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 12:11:14 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 12:11:14 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 12:11:14 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 12:11:17.864: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 12:11:17.865: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 12:11:17.942: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 12:11:17.942: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m1.216566s}&#xA;Mar 21 12:11:17.942: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m1.173626s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 12:11:17.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-downward-api-zzt7k&#34; for this suite.&#xA;Mar 21 12:11:27.978: INFO: namespace: e2e-tests-downward-api-zzt7k, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Downward API volume should update labels on modification [Conformance] [Volume]" classname="E2eNode Suite" time="40.568100915"></testcase>
      <testcase name="[k8s.io] Pods should support retrieving logs from the container over websockets" classname="E2eNode Suite" time="38.053941676"></testcase>
      <testcase name="[k8s.io] Kubelet Cgroup Manager Pod containers On scheduling a Guaranteed Pod Pod containers should have been created under the cgroup-root" classname="E2eNode Suite" time="40.158531392">
          <failure type="Failure">/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/pods_container_manager_test.go:215&#xA;Expected error:&#xA;    &lt;*errors.errorString | 0xc420e24ef0&gt;: {&#xA;        s: &#34;pod \&#34;podb1bac58a-0e2f-11e7-8677-42010a8c0008\&#34; failed with status: {Phase:Failed Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:12:46 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:12:46 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [containerb1bac5b0-0e2f-11e7-8677-42010a8c0008]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:12:54 +0000 UTC Reason: Message:}] Message: Reason: HostIP:10.140.0.8 PodIP: StartTime:2017-03-21 12:12:46 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:containerb1bac5b0-0e2f-11e7-8677-42010a8c0008 State:{Waiting:nil Running:nil Terminated:&amp;ContainerStateTerminated{ExitCode:127,Signal:0,Reason:Failed,Message:,StartedAt:0001-01-01 00:00:00 +0000 UTC,FinishedAt:2017-03-21 12:12:53 +0000 UTC,ContainerID:hyper://dd5f94cc8468ee65c046aefac3a7bd43f6f545cb20f6df696266a512d00e9c62,}} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff ImageID:sha256:0cb40641836c461bc97c793971d84d758371ed682042457523e4ae701efe7ec9 ContainerID:hyper://dd5f94cc8468ee65c046aefac3a7bd43f6f545cb20f6df696266a512d00e9c62}] QOSClass:BestEffort}&#34;,&#xA;    }&#xA;    pod &#34;podb1bac58a-0e2f-11e7-8677-42010a8c0008&#34; failed with status: {Phase:Failed Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:12:46 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:12:46 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [containerb1bac5b0-0e2f-11e7-8677-42010a8c0008]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2017-03-21 12:12:54 +0000 UTC Reason: Message:}] Message: Reason: HostIP:10.140.0.8 PodIP: StartTime:2017-03-21 12:12:46 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:containerb1bac5b0-0e2f-11e7-8677-42010a8c0008 State:{Waiting:nil Running:nil Terminated:&amp;ContainerStateTerminated{ExitCode:127,Signal:0,Reason:Failed,Message:,StartedAt:0001-01-01 00:00:00 +0000 UTC,FinishedAt:2017-03-21 12:12:53 +0000 UTC,ContainerID:hyper://dd5f94cc8468ee65c046aefac3a7bd43f6f545cb20f6df696266a512d00e9c62,}} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff ImageID:sha256:0cb40641836c461bc97c793971d84d758371ed682042457523e4ae701efe7ec9 ContainerID:hyper://dd5f94cc8468ee65c046aefac3a7bd43f6f545cb20f6df696266a512d00e9c62}] QOSClass:BestEffort}&#xA;not to have occurred&#xA;/root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/pods_container_manager_test.go:205</failure>
          <system-out>[BeforeEach] [k8s.io] Kubelet Cgroup Manager&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:119&#xA;�[1mSTEP�[0m: Creating a kubernetes client&#xA;�[1mSTEP�[0m: Building a namespace api object&#xA;Mar 21 12:12:46.612: INFO: Skipping waiting for service account&#xA;[It] Pod containers should have been created under the cgroup-root&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e_node/pods_container_manager_test.go:215&#xA;�[1mSTEP�[0m: Creating a Guaranteed pod in Namespace&#xA;�[1mSTEP�[0m: Checking if the pod cgroup was created&#xA;Mar 21 12:12:46.617: INFO: Waiting up to 5m0s for pod podb1bac58a-0e2f-11e7-8677-42010a8c0008 status to be success or failure&#xA;Mar 21 12:12:46.618: INFO: Waiting for pod podb1bac58a-0e2f-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-kubelet-cgroup-manager-w7k3l&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (1.014578ms elapsed)&#xA;Mar 21 12:12:48.621: INFO: Waiting for pod podb1bac58a-0e2f-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-kubelet-cgroup-manager-w7k3l&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (2.004387339s elapsed)&#xA;Mar 21 12:12:50.627: INFO: Waiting for pod podb1bac58a-0e2f-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-kubelet-cgroup-manager-w7k3l&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (4.009977649s elapsed)&#xA;Mar 21 12:12:52.631: INFO: Waiting for pod podb1bac58a-0e2f-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-kubelet-cgroup-manager-w7k3l&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (6.014165947s elapsed)&#xA;Mar 21 12:12:54.633: INFO: Waiting for pod podb1bac58a-0e2f-11e7-8677-42010a8c0008 in namespace &#39;e2e-tests-kubelet-cgroup-manager-w7k3l&#39; status to be &#39;success or failure&#39;(found phase: &#34;Pending&#34;, readiness: false) (8.016423086s elapsed)&#xA;[AfterEach] [k8s.io] Kubelet Cgroup Manager&#xA;  /root/go-project/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:120&#xA;�[1mSTEP�[0m: Collecting events from namespace &#34;e2e-tests-kubelet-cgroup-manager-w7k3l&#34;.&#xA;�[1mSTEP�[0m: Found 6 events.&#xA;Mar 21 12:12:56.642: INFO: At 2017-03-21 12:12:52 +0000 UTC - event for podb1ba78d3-0e2f-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/pause-amd64:3.0&#34; already present on machine&#xA;Mar 21 12:12:56.642: INFO: At 2017-03-21 12:12:52 +0000 UTC - event for podb1ba78d3-0e2f-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id 70d9f15de6bc9e5ca438e8ee271f4156a31161244fc925414a2c74e702dce839&#xA;Mar 21 12:12:56.642: INFO: At 2017-03-21 12:12:52 +0000 UTC - event for podb1ba78d3-0e2f-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Started: Started container with id 70d9f15de6bc9e5ca438e8ee271f4156a31161244fc925414a2c74e702dce839&#xA;Mar 21 12:12:56.642: INFO: At 2017-03-21 12:12:53 +0000 UTC - event for podb1bac58a-0e2f-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Pulled: Container image &#34;gcr.io/google_containers/busybox:1.24&#34; already present on machine&#xA;Mar 21 12:12:56.642: INFO: At 2017-03-21 12:12:53 +0000 UTC - event for podb1bac58a-0e2f-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Created: Created container with id dd5f94cc8468ee65c046aefac3a7bd43f6f545cb20f6df696266a512d00e9c62&#xA;Mar 21 12:12:56.642: INFO: At 2017-03-21 12:12:53 +0000 UTC - event for podb1bac58a-0e2f-11e7-8677-42010a8c0008: {kubelet frakti-e2e} Started: Started container with id dd5f94cc8468ee65c046aefac3a7bd43f6f545cb20f6df696266a512d00e9c62&#xA;Mar 21 12:12:56.648: INFO: POD                                      NODE        PHASE    GRACE  CONDITIONS&#xA;Mar 21 12:12:56.648: INFO: podb1ba78d3-0e2f-11e7-8677-42010a8c0008  frakti-e2e  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:12:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:12:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:12:53 +0000 UTC  }]&#xA;Mar 21 12:12:56.648: INFO: podb1bac58a-0e2f-11e7-8677-42010a8c0008  frakti-e2e  Failed          [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:12:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:12:46 +0000 UTC ContainersNotReady containers with unready status: [containerb1bac5b0-0e2f-11e7-8677-42010a8c0008]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2017-03-21 12:12:54 +0000 UTC  }]&#xA;Mar 21 12:12:56.648: INFO: &#xA;Mar 21 12:12:56.652: INFO: &#xA;Logging node info for node frakti-e2e&#xA;Mar 21 12:12:56.655: INFO: Node Info: &amp;Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:frakti-e2e,GenerateName:,Namespace:,SelfLink:/api/v1/nodesfrakti-e2e,UID:464fd7a6-0e28-11e7-a3dc-42010a8c0008,ResourceVersion:4228,Generation:0,CreationTimestamp:2017-03-21 11:19:39 +0000 UTC,DeletionTimestamp:&lt;nil&gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/os: linux,kubernetes.io/hostname: frakti-e2e,},Annotations:map[string]string{volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:NodeSpec{PodCIDR:,ExternalID:frakti-e2e,ProviderID:gce:////5985600149768706345,Unschedulable:false,Taints:[],},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15770382336 0} {&lt;nil&gt;} 15400764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {&lt;nil&gt;} 4 DecimalSI},memory: {{15508238336 0} {&lt;nil&gt;} 15144764Ki BinarySI},pods: {{110 0} {&lt;nil&gt;} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2017-03-21 12:12:54 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2017-03-21 12:12:54 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2017-03-21 12:12:54 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {Ready True 2017-03-21 12:12:54 +0000 UTC 2017-03-21 11:19:39 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{LegacyHostIP 10.140.0.8} {InternalIP 10.140.0.8} {Hostname frakti-e2e}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:24ff1754f521f8ffc0b9d886cd5831f7,SystemUUID:66DF790D-8659-19AF-C8E8-AAAC6BAFD264,BootID:7e239c8e-718c-4421-bc64-180fb95b872d,KernelVersion:3.10.0-514.6.2.el7.x86_64,OSImage:CentOS Linux 7 (Core),ContainerRuntimeVersion:hyper://0.8.0,KubeletVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,KubeProxyVersion:v1.7.0-alpha.0.1397+e3f6f14bf0d1af,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google_containers/node-problem-detector:v0.3.0] 290407887} {[gcr.io/google_containers/volume-nfs:0.8] 247146979} {[gcr.io/google_containers/volume-gluster:0.2] 212127750} {[gcr.io/google_containers/nginx-slim:0.7] 86838142} {[] 47794349} {[gcr.io/google_containers/hostexec:1.2] 13185747} {[gcr.io/google_containers/netexec:1.7] 8016035} {[gcr.io/google_containers/netexec:1.5] 7358440} {[gcr.io/google_containers/netexec:1.4] 7293444} {[gcr.io/google_containers/alpine-with-bash:1.0] 6660469} {[gcr.io/google_containers/serve_hostname:v1.4] 6222101} {[gcr.io/google-containers/stress:v1] 5494760} {[] 5042632} {[gcr.io/authenticated-image-pulling/alpine:3.1] 5038488} {[gcr.io/google_containers/test-webserver:e2e] 4534272} {[gcr.io/google_containers/liveness:e2e] 4387474} {[gcr.io/google_containers/eptest:0.1] 2970692} {[gcr.io/google_containers/mounttest-user:0.5] 1450761} {[gcr.io/google_containers/mounttest:0.8] 1450761} {[gcr.io/google_containers/busybox@sha256:4bdd623e848417d96127e16037743f0cd8b528c026e9175e22a84f639eca58ff gcr.io/google_containers/busybox:1.24] 1113554} {[gcr.io/google_containers/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],},}&#xA;Mar 21 12:12:56.655: INFO: &#xA;Logging kubelet events for node frakti-e2e&#xA;Mar 21 12:12:56.656: INFO: &#xA;Logging pods the kubelet thinks is on node frakti-e2e&#xA;Mar 21 12:12:56.660: INFO: podb1ba78d3-0e2f-11e7-8677-42010a8c0008 started at 2017-03-21 12:12:46 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 12:12:56.661: INFO: &#x9;Container containerb1ba83b4-0e2f-11e7-8677-42010a8c0008 ready: true, restart count 0&#xA;Mar 21 12:12:56.661: INFO: podb1bac58a-0e2f-11e7-8677-42010a8c0008 started at 2017-03-21 12:12:46 +0000 UTC (0+1 container statuses recorded)&#xA;Mar 21 12:12:56.661: INFO: &#x9;Container containerb1bac5b0-0e2f-11e7-8677-42010a8c0008 ready: false, restart count 0&#xA;Mar 21 12:12:56.729: INFO: &#xA;Latency metrics for node frakti-e2e&#xA;Mar 21 12:12:56.729: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m1.216566s}&#xA;Mar 21 12:12:56.729: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:2m1.18373s}&#xA;�[1mSTEP�[0m: Dumping a list of prepulled images on each node&#xA;Mar 21 12:12:56.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready&#xA;�[1mSTEP�[0m: Destroying namespace &#34;e2e-tests-kubelet-cgroup-manager-w7k3l&#34; for this suite.&#xA;Mar 21 12:13:26.755: INFO: namespace: e2e-tests-kubelet-cgroup-manager-w7k3l, resource: bindings, ignored listing per whitelist&#xA;</system-out>
      </testcase>
      <testcase name="[k8s.io] Resource-usage [Serial] [Slow] regular resource usage tracking resource tracking for 105 pods per node [Benchmark]" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Projected should be consumable from pods in volume with mappings and Item Mode set [Conformance] [Volume]" classname="E2eNode Suite" time="18.070948154"></testcase>
      <testcase name="[k8s.io] Probing container with readiness probe that fails should never be ready and never restart [Conformance]" classname="E2eNode Suite" time="85.03952087"></testcase>
      <testcase name="[k8s.io] EmptyDir volumes volume on tmpfs should have the correct mode [Conformance] [Volume]" classname="E2eNode Suite" time="18.072306112"></testcase>
      <testcase name="[k8s.io] Density [Serial] [Slow] create a batch of pods latency/resource should be within limit when create 35 pods with 0s interval [Benchmark]" classname="E2eNode Suite" time="0">
          <skipped></skipped>
      </testcase>
      <testcase name="[k8s.io] Projected should provide container&#39;s memory request [Conformance] [Volume]" classname="E2eNode Suite" time="18.070516192"></testcase>
      <testcase name="[k8s.io] Projected should provide podname as non-root with fsgroup and defaultMode [Feature:FSGroup] [Volume]" classname="E2eNode Suite" time="18.061737699"></testcase>
  </testsuite>